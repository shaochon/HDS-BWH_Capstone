{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/PHShome/cs1839/miniforge3/envs/capstone/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-10-14 09:42:18,911\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to /PHShome/cs1839/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\"\n",
    "import json\n",
    "from huggingface_hub import login\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from vllm import LLM, SamplingParams\n",
    "\n",
    "\n",
    "# Read the JSON config file\n",
    "with open('config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Get the token from the JSON file\n",
    "hg_token = config['HuggingFace']['token']\n",
    "# Login using the token\n",
    "login(token=hg_token)\n",
    "\n",
    "# LLM folder\n",
    "llm_folder = \"/PHShome/jn180/llm_public_host\"\n",
    "# Data folder\n",
    "data_folder = \"/PHShome/cs1839/capstone_data/\"\n",
    "# results table path\n",
    "results_df_path = data_folder + \"results.csv\"\n",
    "\n",
    "# data to inference \n",
    "medication_status_test = pd.read_csv(data_folder + \"medication_status_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draft\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:08<00:00,  2.05s/it]\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/netapp3/raw_data3/share/llm_public_host/Llama-3.1-8B\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    \n",
    "tokenizer.pad_token = tokenizer.eos_token  # Set pad token to eos_token (common for autoregressive models)\n",
    "tokenizer.padding_side = \"left\"  # Set padding to left for autoregressive models\n",
    "\n",
    "# Initialize the pipeline for text generation\n",
    "generator = pipeline(\n",
    "    task=\"text-generation\",\n",
    "    model=model_path,\n",
    "    tokenizer=tokenizer,  # Pass the tokenizer with left padding settings\n",
    "    device=0,  # '0' for GPU, '-1' for CPU\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16} # Use torch.bfloat16 for faster generation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [02:15<00:00, 19.30s/it]\n"
     ]
    }
   ],
   "source": [
    "sub_df = medication_status_test['snippet'].values.tolist()\n",
    "\n",
    "batch_size = 16\n",
    "num_step = len(sub_df) // batch_size + 1 if len(sub_df) % batch_size != 0 else len(sub_df) // batch_size\n",
    "max_token_output = 80\n",
    "response_list = []\n",
    "\n",
    "# Settings for text generation\n",
    "use_sampling = True  # Set to True if you want to use sampling; False for greedy search\n",
    "temperature = 0.1 if use_sampling else None  # Set temperature for sampling; None for greedy\n",
    "top_p = 0.9 if use_sampling else None  # Use top-p sampling only when sampling is enabled\n",
    "\n",
    "# Iterate through batches\n",
    "for i in tqdm(range(num_step)):\n",
    "    input_texts = sub_df[i*batch_size:(i+1)*batch_size]\n",
    "\n",
    "    prompt = \"\"\"\n",
    "Identify and categorize the medications mentioned in the following medical note. Extract all medications the patient has taken before, is currently taking, and any other medications mentioned.\n",
    "Note: Adjust the number of medications in each category based on the input. Write None if no other medication mentioned. Strictly follow the output format.\n",
    "Expected Output Format:\n",
    "\"\n",
    "- Current Medications (Active): [Medication 1], [Medication 2]\n",
    "- Discontinued Medications: [Medication 3], [Medication 4]\n",
    "- Other Mentioned Medications (neither active nor discontinued): [Medication 5], [Medication 6]\n",
    "END\"\n",
    "\n",
    "Input Medical Note:\n",
    "\"\"\"\n",
    "    output = \"\"\"\n",
    "    \\nOutput:\\n\n",
    "    \"\"\"\n",
    "\n",
    "    input_texts = [prompt + text + output for text in input_texts]\n",
    "\n",
    "    # Generate responses for each batch\n",
    "    responses = generator(\n",
    "        input_texts,  # Concatenate the prompt and input texts\n",
    "        max_new_tokens=max_token_output,   # Limit the number of new tokens in the output\n",
    "        pad_token_id=generator.tokenizer.eos_token_id,  # Set the pad_token_id\n",
    "        eos_token_id=generator.tokenizer.eos_token_id,  # Set the eos_token_id\n",
    "        \n",
    "        truncation=True,          # Truncate the input if it's longer than max_token_input\n",
    "        do_sample=use_sampling,   # Sampling or greedy search\n",
    "        temperature=temperature,  # Only set if sampling is enabled\n",
    "        top_p=top_p,              # Only set if sampling is enabled\n",
    "    )\n",
    "\n",
    "    # Loop through each input and its corresponding response\n",
    "    for response in responses:\n",
    "        # Each `response` is a list with one dictionary, so we need to extract the first item\n",
    "        for generated in response:  # Loop through the list in case of multiple generations\n",
    "            # only save the generated output\n",
    "            response_list.append(generated['generated_text'].split(\"\\nOutput:\\n\")[1].split(\"END\")[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1495997/3797027712.py:152: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  result_df._append(new_row, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Model</th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MIT</td>\n",
       "      <td>meta-llama/Meta-Llama-3.1-8B-Instruct</td>\n",
       "      <td>\\nIdentify and categorize the medications ment...</td>\n",
       "      <td>0.602556</td>\n",
       "      <td>0.688087</td>\n",
       "      <td>0.745139</td>\n",
       "      <td>0.629691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dataset                                  Model  \\\n",
       "0     MIT  meta-llama/Meta-Llama-3.1-8B-Instruct   \n",
       "\n",
       "                                              Prompt  Accuracy  Precision  \\\n",
       "0  \\nIdentify and categorize the medications ment...  0.602556   0.688087   \n",
       "\n",
       "     Recall        F1  \n",
       "0  0.745139  0.629691  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_output(input_df, response_list):\n",
    "    \"\"\"\n",
    "    Processes a list of LLM responses to extract medication information and adds it to the input DataFrame.\n",
    "\n",
    "    This function takes an input DataFrame (`input_df`) and a list of responses (`response_list`),\n",
    "    where each response contains categorized medication data. The function extracts three categories\n",
    "    of medications (active, discontinued, and neither), formats them into lists, and creates a new\n",
    "    DataFrame with three columns:\n",
    "    \n",
    "    - `active_medications`: Medications that the patient is currently taking.\n",
    "    - `discontinued_medications`: Medications that the patient has taken but has since discontinued.\n",
    "    - `neither_medications`: Medications that are mentioned but are neither currently taken nor discontinued.\n",
    "\n",
    "    The new DataFrame with these three columns is concatenated with the `input_df` and returned.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    input_df : pd.DataFrame\n",
    "        The original input DataFrame, which will be concatenated with the extracted medication data.\n",
    "    \n",
    "    response_list : list of str\n",
    "        A list of strings containing the LLM responses. Each response includes a categorized list of medications\n",
    "        (active, discontinued, and neither).\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        A new DataFrame that concatenates the `input_df` with the extracted medication data.\n",
    "        The resulting DataFrame will have the original columns from `input_df`, plus three new columns:\n",
    "        `active_medications`, `discontinued_medications`, and `neither_medications`, each containing a list of medications.\n",
    "\n",
    "    Example:\n",
    "    --------\n",
    "    >>> input_df = pd.DataFrame({'notes': [\"Note 1\", \"Note 2\"]})\n",
    "    >>> response_list = [\n",
    "    >>>     'Current Medications (Active): Aspirin\\nDiscontinued Medications: Atenolol\\nOther Mentioned Medications: Ibuprofen',\n",
    "    >>>     'Current Medications (Active): None\\nDiscontinued Medications: Metoprolol\\nOther Mentioned Medications: Acetaminophen'\n",
    "    >>> ]\n",
    "    >>> final_df = process_output(input_df, response_list)\n",
    "    >>> print(final_df)\n",
    "    \n",
    "    Output:\n",
    "    -------\n",
    "        notes    active_medications     discontinued_medications    neither_medications\n",
    "        Note 1   [Aspirin]              [Atenolol]                  [Ibuprofen]\n",
    "        Note 2   []                     [Metoprolol]                [Acetaminophen]\n",
    "    \"\"\"\n",
    "    # Initialize lists to store the medications for each category\n",
    "    active_medications_list = []\n",
    "    discontinued_medications_list = []\n",
    "    neither_medications_list = []\n",
    "\n",
    "    # Loop through each response in the response_list\n",
    "    for response in response_list:\n",
    "        # Extract the active, discontinued, and neither medications using regular expressions\n",
    "        active_medications = re.search(r'Current Medications \\(Active\\):\\s*(.*)', response)\n",
    "        discontinued_medications = re.search(r'Discontinued Medications:\\s*(.*)', response)\n",
    "        neither_medications = re.search(r'Other Mentioned Medications.*:\\s*(.*)', response)\n",
    "\n",
    "        # Convert to lists and handle None cases\n",
    "        active_medications = active_medications.group(1).split(', ') if active_medications and active_medications.group(1) != \"None\" else []\n",
    "        discontinued_medications = discontinued_medications.group(1).split(', ') if discontinued_medications and discontinued_medications.group(1) != \"None\" else []\n",
    "        neither_medications = neither_medications.group(1).split(', ') if neither_medications and neither_medications.group(1) != \"None\" else []\n",
    "\n",
    "        # Append each category list to their respective main lists\n",
    "        active_medications_list.append(active_medications)\n",
    "        discontinued_medications_list.append(discontinued_medications)\n",
    "        neither_medications_list.append(neither_medications)\n",
    "\n",
    "    # Create a new DataFrame from the lists\n",
    "    output_df = pd.DataFrame({\n",
    "        'active_medications_pred': active_medications_list,\n",
    "        'discontinued_medications_pred': discontinued_medications_list,\n",
    "        'neither_medications_pred': neither_medications_list\n",
    "    })\n",
    "\n",
    "    # Concatenate the input_df with the output_df by rows\n",
    "    result_df = pd.concat([input_df, output_df], axis=1)\n",
    "\n",
    "    return result_df\n",
    "\n",
    "def calculate_row_metrics(df):\n",
    "    columns = df.columns.tolist()\n",
    "    # Iterate over the three categories\n",
    "    for category in ['active_medications', 'discontinued_medications', 'neither_medications']:\n",
    "        true_col = category\n",
    "        pred_col = category + '_pred'\n",
    "\n",
    "        # Check the type of true_col, if not list, use eval to convert back\n",
    "        if not isinstance(df[true_col][0], list):\n",
    "            df[true_col] = df[true_col].apply(lambda x: eval(x))\n",
    "\n",
    "        # Initialize columns to store row-wise metrics\n",
    "        df.loc[:, 'avg_precision'] = np.nan\n",
    "        df.loc[:, 'avg_recall'] = np.nan\n",
    "        df.loc[:, 'avg_f1'] = np.nan\n",
    "        df.loc[:, 'avg_accuracy'] = np.nan\n",
    "\n",
    "        # For each row, compute metrics\n",
    "        for index, row in df.iterrows():\n",
    "            # Convert lists to sets for easier comparison\n",
    "            true_set = set(row[true_col])\n",
    "            pred_set = set(row[pred_col])\n",
    "            \n",
    "            # Check if both sets are empty\n",
    "            if not true_set and not pred_set:\n",
    "                precision, recall, f1, accuracy = 1.0, 1.0, 1.0, 1.0  # perfect scores when both are empty\n",
    "            else:\n",
    "                # Create binary lists: 1 if medication is present, 0 otherwise\n",
    "                all_medications = list(true_set.union(pred_set))\n",
    "                true_binary = [1 if med in true_set else 0 for med in all_medications]\n",
    "                pred_binary = [1 if med in pred_set else 0 for med in all_medications]\n",
    "\n",
    "                # Calculate precision, recall, F1, accuracy\n",
    "                precision = precision_score(true_binary, pred_binary, zero_division=1)\n",
    "                recall = recall_score(true_binary, pred_binary, zero_division=1)\n",
    "                f1 = f1_score(true_binary, pred_binary, zero_division=1)\n",
    "                accuracy = accuracy_score(true_binary, pred_binary)\n",
    "\n",
    "            # Append the metrics to the DataFrame\n",
    "            df.loc[index, f'{category}_precision'] = precision\n",
    "            df.loc[index, f'{category}_recall'] = recall\n",
    "            df.loc[index, f'{category}_f1'] = f1\n",
    "            df.loc[index, f'{category}_accuracy'] = accuracy\n",
    "        \n",
    "    # get the average of each metric and append to a column as avg_precision, avg_recall, avg_f1, avg_accuracy\n",
    "    df['avg_precision'] = df[['active_medications_precision', 'discontinued_medications_precision', 'neither_medications_precision']].mean(axis=1)\n",
    "    df['avg_recall'] = df[['active_medications_recall', 'discontinued_medications_recall', 'neither_medications_recall']].mean(axis=1)\n",
    "    df['avg_f1'] = df[['active_medications_f1', 'discontinued_medications_f1', 'neither_medications_f1']].mean(axis=1)\n",
    "    df['avg_accuracy'] = df[['active_medications_accuracy', 'discontinued_medications_accuracy', 'neither_medications_accuracy']].mean(axis=1)\n",
    "\n",
    "    return df[columns+['avg_precision', 'avg_recall', 'avg_f1', 'avg_accuracy']]\n",
    "\n",
    "\n",
    "df_w_classifications = process_output(medication_status_test, response_list)\n",
    "df_w_row_metrics = calculate_row_metrics(df_w_classifications)\n",
    "\n",
    "result_df = pd.read_csv(data_folder+'results.csv')\n",
    "metrics_mean = df_w_row_metrics[['avg_precision', 'avg_recall', 'avg_f1', 'avg_accuracy']].mean(axis=0)\n",
    "\n",
    "# Define your result row\n",
    "new_row = {\n",
    "    'Dataset': 'MIT',\n",
    "    'Model': model_path.split('/')[-1],\n",
    "    'Prompt': prompt,\n",
    "    'Accuracy': metrics_mean.get('avg_accuracy', np.nan),\n",
    "    'Precision': metrics_mean.get('avg_precision', np.nan),\n",
    "    'Recall': metrics_mean.get('avg_recall', np.nan),\n",
    "    'F1': metrics_mean.get('avg_f1', np.nan)\n",
    "}\n",
    "\n",
    "result_df._append(new_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "# 1. Function to initialize model and tokenizer\n",
    "def initialize_model(model_path, device=0, use_fp16=True):\n",
    "    \"\"\"\n",
    "    Initializes the model and tokenizer for text generation.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    model_path : str\n",
    "        Path of the model to be loaded.\n",
    "    device : int\n",
    "        Device to use, 0 for GPU and -1 for CPU.\n",
    "    use_fp16 : bool\n",
    "        Whether to use FP16 for inference.\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "    generator : pipeline\n",
    "        A HuggingFace pipeline ready for text generation.\n",
    "    \"\"\"\n",
    "    # Load tokenizer and set padding side to left\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "        \n",
    "    tokenizer.pad_token = tokenizer.eos_token  # Set pad token to eos_token (common for autoregressive models)\n",
    "    tokenizer.padding_side = \"left\"  # Set padding to left for autoregressive models\n",
    "\n",
    "    # Initialize the pipeline for text generation\n",
    "    generator = pipeline(\n",
    "        task=\"text-generation\",\n",
    "        model=model_path,\n",
    "        tokenizer=tokenizer,  # Pass the tokenizer with left padding settings\n",
    "        device=device,  # '0' for GPU, '-1' for CPU\n",
    "        model_kwargs={\"torch_dtype\": torch.float16} if use_fp16 else {}\n",
    "    )\n",
    "    return generator\n",
    "\n",
    "# 2. Function to generate batch responses using the model\n",
    "    return response_list\n",
    "\n",
    "# 2. Function to generate batch responses using the model\n",
    "def generate_responses(input_df, batch_size, generator, prompt_template, max_token_output=80, use_sampling=True):\n",
    "    \"\"\"\n",
    "    Generate text responses in batches using the generator.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    input_df : list of str\n",
    "        List of input texts to run inference on.\n",
    "    batch_size : int\n",
    "        Size of each batch for inference.\n",
    "    generator : pipeline\n",
    "        HuggingFace pipeline initialized for text generation.\n",
    "    prompt_template : str\n",
    "        The template for the prompt to be used.\n",
    "    max_token_output : int\n",
    "        Maximum number of tokens to generate.\n",
    "    use_sampling : bool\n",
    "        Whether to use sampling or greedy decoding.\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "    response_list : list of str\n",
    "        List of generated responses.\n",
    "    \"\"\"\n",
    "    sub_df = input_df['snippet'].values.tolist()\n",
    "\n",
    "    response_list = []\n",
    "    num_step = len(sub_df) // batch_size + (1 if len(sub_df) % batch_size != 0 else 0)\n",
    "    temperature = 0.9 if use_sampling else None\n",
    "    top_p = 0.9 if use_sampling else None\n",
    "    top_k = 20 if use_sampling else None\n",
    "\n",
    "    for i in tqdm(range(num_step)):\n",
    "        input_texts = sub_df[i*batch_size:(i+1)*batch_size]\n",
    "        input_texts = [prompt_template.format(text) for text in input_texts]\n",
    "\n",
    "        responses = generator(\n",
    "            input_texts,\n",
    "            max_new_tokens=max_token_output,  # Ensure this is used for token generation\n",
    "            pad_token_id=generator.tokenizer.eos_token_id,\n",
    "            eos_token_id=generator.tokenizer.eos_token_id,\n",
    "            truncation=True,\n",
    "            do_sample=use_sampling,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            top_k=top_k)\n",
    "\n",
    "        # Process the output\n",
    "        for response in responses:\n",
    "            for generated in response:\n",
    "                # Extract relevant part of the response and append to list\n",
    "                response_list.append(generated['generated_text'].split(\"\\nOutput:\\n\")[1].split(\"END\")[0])\n",
    "    \n",
    "    return response_list\n",
    "\n",
    "# 3. Function to process the LLM output\n",
    "def process_output(input_df, response_list):\n",
    "    \"\"\"\n",
    "    Processes a list of LLM responses to extract medication information and adds it to the input DataFrame.\n",
    "\n",
    "    This function takes an input DataFrame (`input_df`) and a list of responses (`response_list`),\n",
    "    where each response contains categorized medication data. The function extracts three categories\n",
    "    of medications (active, discontinued, and neither), formats them into lists, and creates a new\n",
    "    DataFrame with three columns:\n",
    "    \n",
    "    - `active_medications`: Medications that the patient is currently taking.\n",
    "    - `discontinued_medications`: Medications that the patient has taken but has since discontinued.\n",
    "    - `neither_medications`: Medications that are mentioned but are neither currently taken nor discontinued.\n",
    "\n",
    "    The new DataFrame with these three columns is concatenated with the `input_df` and returned.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    input_df : pd.DataFrame\n",
    "        The original input DataFrame, which will be concatenated with the extracted medication data.\n",
    "    \n",
    "    response_list : list of str\n",
    "        A list of strings containing the LLM responses. Each response includes a categorized list of medications\n",
    "        (active, discontinued, and neither).\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        A new DataFrame that concatenates the `input_df` with the extracted medication data.\n",
    "        The resulting DataFrame will have the original columns from `input_df`, plus three new columns:\n",
    "        `active_medications`, `discontinued_medications`, and `neither_medications`, each containing a list of medications.\n",
    "\n",
    "    Example:\n",
    "    --------\n",
    "    >>> input_df = pd.DataFrame({'notes': [\"Note 1\", \"Note 2\"]})\n",
    "    >>> response_list = [\n",
    "    >>>     'Current Medications (Active): Aspirin\\nDiscontinued Medications: Atenolol\\nOther Mentioned Medications: Ibuprofen',\n",
    "    >>>     'Current Medications (Active): None\\nDiscontinued Medications: Metoprolol\\nOther Mentioned Medications: Acetaminophen'\n",
    "    >>> ]\n",
    "    >>> final_df = process_output(input_df, response_list)\n",
    "    >>> print(final_df)\n",
    "    \n",
    "    Output:\n",
    "    -------\n",
    "        notes    active_medications     discontinued_medications    neither_medications\n",
    "        Note 1   [Aspirin]              [Atenolol]                  [Ibuprofen]\n",
    "        Note 2   []                     [Metoprolol]                [Acetaminophen]\n",
    "    \"\"\"\n",
    "\n",
    "    # check if input_df.active_medications[0] is a list, if not, apply eval and lower to active_medications, discontinued_medications, neither_medications\n",
    "    import ast\n",
    "    if not isinstance(input_df.active_medications.iloc[0], list):\n",
    "        for col in ['active_medications', 'discontinued_medications', 'neither_medications']:\n",
    "            input_df.loc[:,col] = input_df[col].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "            input_df.loc[:,col] = input_df[col].apply(lambda meds: [med.lower() for med in meds])\n",
    "        \n",
    "\n",
    "    # Initialize lists to store the medications for each category\n",
    "    active_medications_list = []\n",
    "    discontinued_medications_list = []\n",
    "    neither_medications_list = []\n",
    "\n",
    "    # Loop through each response in the response_list\n",
    "    for response in response_list:\n",
    "        # Extract the active, discontinued, and neither medications using regular expressions\n",
    "        active_medications = re.search(r'Current Medications \\(Active\\):\\s*(.*)', response)\n",
    "        discontinued_medications = re.search(r'Discontinued Medications:\\s*(.*)', response)\n",
    "        neither_medications = re.search(r'Other Mentioned Medications.*:\\s*(.*)', response)\n",
    "        \n",
    "       # Convert to lists and handle None cases\n",
    "        active_medications = active_medications.group(1).split(', ') if active_medications and active_medications.group(1) != \"None\" else []\n",
    "        discontinued_medications = discontinued_medications.group(1).split(', ') if discontinued_medications and discontinued_medications.group(1) != \"None\" else []\n",
    "        neither_medications = neither_medications.group(1).split(', ') if neither_medications and neither_medications.group(1) != \"None\" else []\n",
    "                               \n",
    "        # Append each category list to their respective main lists\n",
    "        active_medications_list.append([x.lower() for x in active_medications] if active_medications else [])\n",
    "        discontinued_medications_list.append([x.lower() for x in discontinued_medications] if discontinued_medications else [])\n",
    "        neither_medications_list.append([x.lower() for x in neither_medications] if neither_medications else [])\n",
    "\n",
    "    # Create a new DataFrame from the lists\n",
    "    output_df = pd.DataFrame({\n",
    "        'active_medications_pred': [med_list if med_list else [] for med_list in active_medications_list],\n",
    "        'discontinued_medications_pred': [med_list if med_list else [] for med_list in discontinued_medications_list],\n",
    "        'neither_medications_pred': [med_list if med_list else [] for med_list in neither_medications_list]\n",
    "    })\n",
    "\n",
    "    \n",
    "    # Concatenate the input_df with the output_df by rows\n",
    "    # Ensure the indices of both dataframes are aligned\n",
    "    output_df.reset_index(drop=True, inplace=True)\n",
    "    input_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Concatenate the input_df with the output_df by columns (side by side)\n",
    "    result_df = pd.concat([input_df, output_df], axis=1)\n",
    "\n",
    "    return result_df\n",
    "\n",
    "# 4. Function to calculate metrics (Precision, Recall, F1, Accuracy)\n",
    "def calculate_row_metrics(df):\n",
    "    columns = df.columns.tolist()\n",
    "\n",
    "    # Initialize columns to store row-wise metrics\n",
    "    df.loc[:, 'extraction_precision'] = np.nan\n",
    "    df.loc[:, 'extraction_recall'] = np.nan\n",
    "    df.loc[:, 'conditional_accuracy'] = np.nan\n",
    "    df.loc[:, 'conditional_macro_f1'] = np.nan\n",
    "    df.loc[:, 'conditional_macro_precision'] = np.nan\n",
    "    df.loc[:, 'conditional_macro_recall'] = np.nan\n",
    "\n",
    "    # Helper function to compute F1 score\n",
    "    def compute_conditional_metrics(true_set, pred_set):\n",
    "        tp = len(true_set.intersection(pred_set))\n",
    "        precision = tp / len(pred_set) if len(pred_set) > 0 else 0\n",
    "        recall = tp / len(true_set) if len(true_set) > 0 else 0\n",
    "        f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        return f1, precision, recall\n",
    "\n",
    "    # first compute the extraction metrics\n",
    "    for index, row in df.iterrows():\n",
    "        # get the elements in active_medications_pred, discontinued_medications_pred, neither_medications_pred into a set\n",
    "        pred_set = set(row['active_medications_pred'] + row['discontinued_medications_pred'] + row['neither_medications_pred'])\n",
    "        true_set = set(row['active_medications'] + row['discontinued_medications'] + row['neither_medications'])\n",
    "\n",
    "        # get the intersection of the two sets\n",
    "        intersection = pred_set.intersection(true_set)\n",
    "\n",
    "        # calculate precision, recall\n",
    "        precision = len(intersection) / len(pred_set) if len(pred_set) != 0 else 0\n",
    "        recall = len(intersection) / len(true_set) if len(true_set) != 0 else 0\n",
    "\n",
    "        df.loc[index, 'extraction_precision'] = precision\n",
    "        df.loc[index, 'extraction_recall'] = recall\n",
    "    \n",
    "\n",
    "        ##### then compute the conditional metrics\n",
    "\n",
    "        # Get the true and predicted sets for each category\n",
    "        correctly_extracted_active = set(row['active_medications']).intersection(intersection)\n",
    "        correctly_extracted_discontinued = set(row['discontinued_medications']).intersection(intersection)\n",
    "        correctly_extracted_neither = set(row['neither_medications']).intersection(intersection)\n",
    "\n",
    "        active_f1, active_precision, active_recall = compute_conditional_metrics(correctly_extracted_active, set(row['active_medications_pred']))\n",
    "        discontinued_f1, discontinued_precision, discontinued_recall = compute_conditional_metrics(correctly_extracted_discontinued, set(row['discontinued_medications_pred']))\n",
    "        neither_f1, neither_precision, neither_recall = compute_conditional_metrics(correctly_extracted_neither, set(row['neither_medications_pred']))\n",
    "        \n",
    "        # Calculate the macro metrics\n",
    "        macro_f1 = (active_f1 + discontinued_f1 + neither_f1) / 3\n",
    "        macro_precision = (active_precision + discontinued_precision + neither_precision) / 3\n",
    "        macro_recall = (active_recall + discontinued_recall + neither_recall) / 3\n",
    "\n",
    "        ## Calculate conditional accuracy\n",
    "        # get the true set in the intersection\n",
    "        active_true = set(row['active_medications']).intersection(intersection)\n",
    "        discontinued_true = set(row['discontinued_medications']).intersection(intersection)\n",
    "        neither_true = set(row['neither_medications']).intersection(intersection)\n",
    "\n",
    "        # get the correct predictions\n",
    "        correct_preds = len(active_true.intersection(set(row['active_medications_pred']))) + \\\n",
    "                        len(discontinued_true.intersection(set(row['discontinued_medications_pred']))) + \\\n",
    "                        len(neither_true.intersection(set(row['neither_medications_pred'])))\n",
    "\n",
    "        acc = correct_preds / len(intersection) if len(intersection) > 0 else 0\n",
    "        \n",
    "        # Update DataFrame with the calculated metrics\n",
    "        df.loc[index, 'conditional_accuracy'] = acc\n",
    "        df.loc[index, 'conditional_macro_f1'] = macro_f1\n",
    "        df.loc[index, 'conditional_macro_precision'] = macro_precision\n",
    "        df.loc[index, 'conditional_macro_recall'] = macro_recall\n",
    "\n",
    "    return df\n",
    "\n",
    "# 5. Main function to tie everything together\n",
    "def run_pipeline(model_path, input_df, prompt_template, batch_size=16, max_token_output=80, use_sampling=True):\n",
    "    \"\"\"\n",
    "    Main function to run the text generation pipeline and compute metrics.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    model_path : str\n",
    "        The path of the model to be used.\n",
    "    input_df : pd.DataFrame\n",
    "        The data to be inferred.\n",
    "    prompt_template : str\n",
    "        Template for constructing the prompts.\n",
    "    batch_size : int\n",
    "        Number of examples per batch.\n",
    "    max_token_output : int\n",
    "        Maximum number of tokens to generate.\n",
    "    use_sampling : bool\n",
    "        Whether to use sampling (or greedy decoding).\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "    result_df : pd.DataFrame\n",
    "        DataFrame with the processed outputs and calculated metrics.\n",
    "    \"\"\"\n",
    "    # Initialize the model\n",
    "    generator = initialize_model(model_path, device=0)\n",
    "\n",
    "    # Generate responses\n",
    "    response_list = generate_responses(input_df, batch_size, generator, prompt_template, max_token_output, use_sampling)\n",
    "\n",
    "    # Process the responses to categorize medications\n",
    "    df_w_classifications = process_output(input_df, response_list)\n",
    "\n",
    "    # Calculate row-level metrics\n",
    "    df_w_metrics = calculate_row_metrics(df_w_classifications)\n",
    "\n",
    "    # Return the final DataFrame with metrics\n",
    "    return df_w_classifications\n",
    "\n",
    "# 6. Function to benchmark the model\n",
    "def benchmark_model(name_dataset, model_path, prompt_template, input_df, data_folder, result_df_path, use_sampling=True, batch_size=16, max_token_output=80):\n",
    "\n",
    "    # Run the pipeline\n",
    "    df_w_row_metrics = run_pipeline(model_path=model_path, \n",
    "                                    input_df=input_df, \n",
    "                                    prompt_template=prompt_template, \n",
    "                                    use_sampling=use_sampling,\n",
    "                                    batch_size=batch_size, \n",
    "                                    max_token_output=max_token_output)\n",
    "\n",
    "    result_df = pd.read_csv(data_folder+'results.csv')\n",
    "    metrics_mean = df_w_row_metrics[['extraction_precision', 'extraction_recall', 'conditional_accuracy', 'conditional_macro_f1', 'conditional_macro_precision', 'conditional_macro_recall']].mean(axis=0)\n",
    "\n",
    "    # Define your result row\n",
    "    new_row = {\n",
    "        'Dataset': name_dataset,\n",
    "        'Model': model_path.split('/')[-1],\n",
    "        'Prompt': prompt_template,\n",
    "        'extractionn_precision': metrics_mean.get('extraction_precision', np.nan),\n",
    "        'extraction_recall': metrics_mean.get('extraction_recall', np.nan),\n",
    "        'conditional_accuracy': metrics_mean.get('conditional_accuracy', np.nan),\n",
    "        'conditional_macro_f1': metrics_mean.get('conditional_macro_f1', np.nan),\n",
    "        'conditional_macro_precision': metrics_mean.get('conditional_macro_precision', np.nan),\n",
    "        'conditional_macro_recall': metrics_mean.get('conditional_macro_recall', np.nan)\n",
    "    }\n",
    "\n",
    "    result_df = result_df._append(new_row, ignore_index=True).round(3)\n",
    "    result_df.to_csv(result_df_path, index=False)\n",
    "\n",
    "\n",
    "def clear_cuda_memory():\n",
    "    # Clear the cache\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # Run garbage collection\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  1.95it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.07s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>snippet</th>\n",
       "      <th>active_medications</th>\n",
       "      <th>discontinued_medications</th>\n",
       "      <th>neither_medications</th>\n",
       "      <th>active_medications_pred</th>\n",
       "      <th>discontinued_medications_pred</th>\n",
       "      <th>neither_medications_pred</th>\n",
       "      <th>extraction_precision</th>\n",
       "      <th>extraction_recall</th>\n",
       "      <th>conditional_accuracy</th>\n",
       "      <th>conditional_macro_f1</th>\n",
       "      <th>conditional_macro_precision</th>\n",
       "      <th>conditional_macro_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>96</td>\n",
       "      <td>She did have a capsule study done during her p...</td>\n",
       "      <td>[imuran, remicade]</td>\n",
       "      <td>[6 mp]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[iv imuran]</td>\n",
       "      <td>[6 mp]</td>\n",
       "      <td>[remicade, capsule study]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                            snippet  \\\n",
       "0     96  She did have a capsule study done during her p...   \n",
       "\n",
       "   active_medications discontinued_medications neither_medications  \\\n",
       "0  [imuran, remicade]                   [6 mp]                  []   \n",
       "\n",
       "  active_medications_pred discontinued_medications_pred  \\\n",
       "0             [iv imuran]                        [6 mp]   \n",
       "\n",
       "    neither_medications_pred  extraction_precision  extraction_recall  \\\n",
       "0  [remicade, capsule study]                   0.5           0.666667   \n",
       "\n",
       "   conditional_accuracy  conditional_macro_f1  conditional_macro_precision  \\\n",
       "0                   0.5              0.333333                     0.333333   \n",
       "\n",
       "   conditional_macro_recall  \n",
       "0                  0.333333  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_model_paths ={   \n",
    "    # \"Bio_ClinicalBERT\": \"/PHShome/jn180/llm_public_host/Bio_ClinicalBERT\",\n",
    "\n",
    "    # \"Llama-3.1-8B\": \"/netapp3/raw_data3/share/llm_public_host/Llama-3.1-8B\",\n",
    "    # \"Llama-3.1-8B-Instruct\": \"/netapp3/raw_data3/share/llm_public_host/Llama-3.1-8B-Instruct\",\n",
    "\n",
    "    # \"Llama-3.2-1B-Instruct\": \"/netapp3/raw_data3/share/llm_public_host/Llama-3.2-1B-Instruct\",\n",
    "    # \"Llama-3.2-3B-Instruct\": \"/netapp3/raw_data3/share/llm_public_host/Llama-3.2-3B-Instruct\",\n",
    "\n",
    "    # \"Qwen2-7B-Instruct\": \"/PHShome/jn180/llm_public_host/Qwen2-7B-Instruct\",\n",
    "    # \"Qwen2.5-14B-Instruct\": \"/netapp3/raw_data3/share/llm_public_host/Qwen2.5-14B-Instruct\",\n",
    "\n",
    "    # \"meditron-7b\": \"/PHShome/jn180/llm_public_host/meditron-7b\",\n",
    "\n",
    "    \"Mistral-7B-Instruct-v0.3\": \"/netapp3/raw_data3/share/llm_public_host/Mistral-7B-Instruct-v0.3\"\n",
    "\n",
    "}\n",
    "\n",
    "import os\n",
    "# Set the environment variable to specify the GPUs\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "\n",
    "name_dataset = \"MIT\"\n",
    "data_folder = \"/PHShome/cs1839/capstone_data/\"\n",
    "results_df_path = data_folder + \"results.csv\"\n",
    "medication_status_test = pd.read_csv(data_folder + \"medication_status_test.csv\")\n",
    "\n",
    "# prompt_template = \"\"\"\n",
    "# Identify and categorize the medications mentioned in the following medical note. Extract all medications the patient has taken before, is currently taking, and any other medications mentioned.\n",
    "# Note: Adjust the number of medications in each category based on the input. Write None if no other medication mentioned. Strictly follow the output format.\n",
    "# Expected Output Format:\n",
    "# \"\n",
    "# - Current Medications (Active): Medication_1, Medication_2\n",
    "# - Discontinued Medications: Medication_3, Medication_4\n",
    "# - Other Mentioned Medications (neither active nor discontinued): Medication_5, Medication_6\n",
    "# END\"\n",
    "\n",
    "# Input Medical Note:\n",
    "# {}\n",
    "\n",
    "# Output:\n",
    "# \"\"\"\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "Input Medical Note:\n",
    "{}\n",
    "\n",
    "Create a bulleted list of which medications are mentioned and whether they are active, discontinued, or neither.\n",
    "\n",
    "Expected Output Format:\n",
    "\"\n",
    "- Current Medications (Active): Medication_1, Medication_2\n",
    "- Discontinued Medications: Medication_3, Medication_4\n",
    "- Other Mentioned Medications (neither active nor discontinued): Medication_5, Medication_6\n",
    "END\"\n",
    "\n",
    "Output:\n",
    "\"\"\"\n",
    "\n",
    "for model_name, model_path in name_model_paths.items():\n",
    "    df = run_pipeline(model_path=model_path,\n",
    "                        input_df=medication_status_test[medication_status_test['index']==96],\n",
    "                        prompt_template=prompt_template,\n",
    "                        batch_size=16,\n",
    "                        max_token_output=80,\n",
    "                        use_sampling=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  4.81it/s]\n",
      "100%|██████████| 4/4 [01:24<00:00, 21.05s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  4.83it/s]\n",
      "100%|██████████| 4/4 [02:21<00:00, 35.28s/it]\n",
      "100%|██████████| 4/4 [01:08<00:00, 17.14s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.70it/s]\n",
      "100%|██████████| 4/4 [01:56<00:00, 29.00s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  4.78it/s]\n",
      "100%|██████████| 4/4 [01:46<00:00, 26.63s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 8/8 [00:01<00:00,  4.78it/s]\n",
      "100%|██████████| 4/4 [03:36<00:00, 54.22s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 8/8 [00:01<00:00,  4.87it/s]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "100%|██████████| 4/4 [02:07<00:00, 31.97s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  4.80it/s]\n",
      "100%|██████████| 7/7 [02:45<00:00, 23.60s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  4.77it/s]\n",
      "100%|██████████| 7/7 [05:53<00:00, 50.56s/it]\n",
      "100%|██████████| 7/7 [02:49<00:00, 24.26s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.72it/s]\n",
      "100%|██████████| 7/7 [04:50<00:00, 41.46s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  4.68it/s]\n",
      "100%|██████████| 7/7 [04:02<00:00, 34.68s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 8/8 [00:01<00:00,  4.79it/s]\n",
      "100%|██████████| 7/7 [09:02<00:00, 77.57s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 8/8 [00:01<00:00,  4.92it/s]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "100%|██████████| 7/7 [05:19<00:00, 45.65s/it]\n"
     ]
    }
   ],
   "source": [
    "name_model_paths ={   \n",
    "    # \"Bio_ClinicalBERT\": \"/PHShome/jn180/llm_public_host/Bio_ClinicalBERT\",\n",
    "\n",
    "    # \"Llama-3.1-8B\": \"/netapp3/raw_data3/share/llm_public_host/Llama-3.1-8B\",\n",
    "    # \"Llama-3.1-8B-Instruct\": \"/netapp3/raw_data3/share/llm_public_host/Llama-3.1-8B-Instruct\",\n",
    "\n",
    "    # \"Llama-3.2-1B-Instruct\": \"/netapp3/raw_data3/share/llm_public_host/Llama-3.2-1B-Instruct\",\n",
    "    # \"Llama-3.2-3B-Instruct\": \"/netapp3/raw_data3/share/llm_public_host/Llama-3.2-3B-Instruct\",\n",
    "\n",
    "    # \"Qwen2-7B-Instruct\": \"/PHShome/jn180/llm_public_host/Qwen2-7B-Instruct\",\n",
    "    # \"Qwen2.5-14B-Instruct\": \"/netapp3/raw_data3/share/llm_public_host/Qwen2.5-14B-Instruct\",\n",
    "\n",
    "    # \"meditron-7b\": \"/PHShome/jn180/llm_public_host/meditron-7b\",\n",
    "\n",
    "    \"Mistral-7B-Instruct-v0.3\": \"/netapp3/raw_data3/share/llm_public_host/Mistral-7B-Instruct-v0.3\"\n",
    "\n",
    "}\n",
    "\n",
    "import os\n",
    "# Set the environment variable to specify the GPUs\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "\n",
    "name_dataset = \"MIT\"\n",
    "data_folder = \"/PHShome/cs1839/capstone_data/\"\n",
    "results_df_path = data_folder + \"results.csv\"\n",
    "medication_status_test = pd.read_csv(data_folder + \"medication_status_test.csv\")\n",
    "\n",
    "# prompt_template = \"\"\"\n",
    "# Identify and categorize the medications mentioned in the following medical note. Extract all medications the patient has taken before, is currently taking, and any other medications mentioned.\n",
    "# Note: Adjust the number of medications in each category based on the input. Write None if no other medication mentioned. Strictly follow the output format.\n",
    "# Expected Output Format:\n",
    "# \"\n",
    "# - Current Medications (Active): Medication_1, Medication_2\n",
    "# - Discontinued Medications: Medication_3, Medication_4\n",
    "# - Other Mentioned Medications (neither active nor discontinued): Medication_5, Medication_6\n",
    "# END\"\n",
    "\n",
    "# Input Medical Note:\n",
    "# {}\n",
    "\n",
    "# Output:\n",
    "# \"\"\"\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "Input Medical Note:\n",
    "{}\n",
    "\n",
    "Create a bulleted list of which medications are mentioned and whether they are active, discontinued, or neither.\n",
    "\n",
    "Expected Output Format:\n",
    "\"\n",
    "- Current Medications (Active): Medication_1, Medication_2\n",
    "- Discontinued Medications: Medication_3, Medication_4\n",
    "- Other Mentioned Medications (neither active nor discontinued): Medication_5, Medication_6\n",
    "END\"\n",
    "\n",
    "Output:\n",
    "\"\"\"\n",
    "\n",
    "for model_name, model_path in name_model_paths.items():\n",
    "    clear_cuda_memory()\n",
    "    benchmark_model(name_dataset = name_dataset,\n",
    "                    model_path = model_path,\n",
    "                    prompt_template = prompt_template,\n",
    "                    input_df = medication_status_test,\n",
    "                    data_folder = data_folder,\n",
    "                    result_df_path = results_df_path,\n",
    "                    use_sampling = False,\n",
    "                    batch_size = 32,\n",
    "                    max_token_output = 80)\n",
    "\n",
    "\n",
    "\n",
    "name_dataset = \"MIMIC-IV\"\n",
    "mimic_iv = pd.read_csv(data_folder + \"mimic_iv_snippets.csv\")\n",
    "# convert the active, discontinued, and neither medications to contained in a list\n",
    "mimic_iv['active_medications'] = mimic_iv['active_medications'].apply(lambda x: [med.strip() for med in x.split(',')] if x is not np.nan else [])\n",
    "mimic_iv['discontinued_medications'] = mimic_iv['discontinued_medications'].apply(lambda x: [med.strip() for med in x.split(',')] if x is not np.nan else [])\n",
    "mimic_iv['neither_medications'] = mimic_iv['neither_medications'].apply(lambda x: [med.strip() for med in x.split(',')] if x is not np.nan else [])\n",
    "\n",
    "for model_name, model_path in name_model_paths.items():\n",
    "    clear_cuda_memory()\n",
    "    benchmark_model(name_dataset = name_dataset,\n",
    "                    model_path = model_path,\n",
    "                    prompt_template = prompt_template,\n",
    "                    input_df = mimic_iv,\n",
    "                    data_folder = data_folder,\n",
    "                    result_df_path = results_df_path,\n",
    "                    use_sampling = False,\n",
    "                    batch_size = 32,\n",
    "                    max_token_output = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Model</th>\n",
       "      <th>Prompt</th>\n",
       "      <th>extraction_precision</th>\n",
       "      <th>extraction_recall</th>\n",
       "      <th>conditional_accuracy</th>\n",
       "      <th>conditional_macro_f1</th>\n",
       "      <th>conditional_macro_precision</th>\n",
       "      <th>conditional_macro_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MIT</td>\n",
       "      <td>Llama-3.1-70B-Instruct</td>\n",
       "      <td>Input Medical Note:\\n{}\\n\\nCreate a bulleted l...</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MIT</td>\n",
       "      <td>Qwen2-7B-Instruct</td>\n",
       "      <td>Input Medical Note:\\n{}\\n\\nCreate a bulleted l...</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MIMIC-IV</td>\n",
       "      <td>Llama-3.1-70B-Instruct</td>\n",
       "      <td>Input Medical Note:\\n{}\\n\\nCreate a bulleted l...</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MIMIC-IV</td>\n",
       "      <td>Qwen2-7B-Instruct</td>\n",
       "      <td>Input Medical Note:\\n{}\\n\\nCreate a bulleted l...</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.721</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MIT</td>\n",
       "      <td>Qwen2.5-32B-Instruct</td>\n",
       "      <td>Input Medical Note:\\n{}\\n\\nCreate a bulleted l...</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.492</td>\n",
       "      <td>0.507</td>\n",
       "      <td>0.488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MIMIC-IV</td>\n",
       "      <td>Qwen2.5-32B-Instruct</td>\n",
       "      <td>Input Medical Note:\\n{}\\n\\nCreate a bulleted l...</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>MIT</td>\n",
       "      <td>Qwen2-72B-Instruct</td>\n",
       "      <td>Input Medical Note:\\n{}\\n\\nCreate a bulleted l...</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.431</td>\n",
       "      <td>0.439</td>\n",
       "      <td>0.431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MIMIC-IV</td>\n",
       "      <td>Qwen2-72B-Instruct</td>\n",
       "      <td>Input Medical Note:\\n{}\\n\\nCreate a bulleted l...</td>\n",
       "      <td>0.516</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.647</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>MIT</td>\n",
       "      <td>Llama-3.1-8B</td>\n",
       "      <td>Input Medical Note:\\n{}\\n\\nCreate a bulleted l...</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>MIMIC-IV</td>\n",
       "      <td>Llama-3.1-8B</td>\n",
       "      <td>Input Medical Note:\\n{}\\n\\nCreate a bulleted l...</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.691</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>MIT</td>\n",
       "      <td>meditron-70b</td>\n",
       "      <td>Input Medical Note:\\n{}\\n\\nCreate a bulleted l...</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.631</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>MIMIC-IV</td>\n",
       "      <td>meditron-70b</td>\n",
       "      <td>Input Medical Note:\\n{}\\n\\nCreate a bulleted l...</td>\n",
       "      <td>0.634</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.612</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>MIT</td>\n",
       "      <td>Llama-3.2-1B-Instruct</td>\n",
       "      <td>Input Medical Note:\\n{}\\n\\nCreate a bulleted l...</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>MIMIC-IV</td>\n",
       "      <td>Llama-3.2-1B-Instruct</td>\n",
       "      <td>Input Medical Note:\\n{}\\n\\nCreate a bulleted l...</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>MIT</td>\n",
       "      <td>Qwen2.5-14B-Instruct</td>\n",
       "      <td>Input Medical Note:\\n{}\\n\\nCreate a bulleted l...</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.541</td>\n",
       "      <td>0.522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>MIMIC-IV</td>\n",
       "      <td>Qwen2.5-14B-Instruct</td>\n",
       "      <td>Input Medical Note:\\n{}\\n\\nCreate a bulleted l...</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>MIMIC-IV</td>\n",
       "      <td>Mistral-Nemo-Instruct-2407</td>\n",
       "      <td>Input Medical Note:\\n{}\\n\\nCreate a bulleted l...</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>MIT</td>\n",
       "      <td>Mistral-Nemo-Instruct-2407</td>\n",
       "      <td>Input Medical Note:\\n{}\\n\\nCreate a bulleted l...</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>MIT</td>\n",
       "      <td>Llama-3.2-3B-Instruct</td>\n",
       "      <td>Input Medical Note:\\n{}\\n\\nCreate a bulleted l...</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.899</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>MIT</td>\n",
       "      <td>Llama-3.1-8B-Instruct</td>\n",
       "      <td>Input Medical Note:\\n{}\\n\\nCreate a bulleted l...</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.921</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>MIT</td>\n",
       "      <td>Mistral-7B-Instruct-v0.3</td>\n",
       "      <td>Input Medical Note:\\n{}\\n\\nCreate a bulleted l...</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>MIT</td>\n",
       "      <td>Qwen2.5-72B-Instruct</td>\n",
       "      <td>Input Medical Note:\\n{}\\n\\nCreate a bulleted l...</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dataset                       Model  \\\n",
       "14       MIT      Llama-3.1-70B-Instruct   \n",
       "15       MIT           Qwen2-7B-Instruct   \n",
       "16  MIMIC-IV      Llama-3.1-70B-Instruct   \n",
       "17  MIMIC-IV           Qwen2-7B-Instruct   \n",
       "18       MIT        Qwen2.5-32B-Instruct   \n",
       "19  MIMIC-IV        Qwen2.5-32B-Instruct   \n",
       "20       MIT          Qwen2-72B-Instruct   \n",
       "21  MIMIC-IV          Qwen2-72B-Instruct   \n",
       "22       MIT                Llama-3.1-8B   \n",
       "23  MIMIC-IV                Llama-3.1-8B   \n",
       "24       MIT                meditron-70b   \n",
       "25  MIMIC-IV                meditron-70b   \n",
       "26       MIT       Llama-3.2-1B-Instruct   \n",
       "27  MIMIC-IV       Llama-3.2-1B-Instruct   \n",
       "28       MIT        Qwen2.5-14B-Instruct   \n",
       "29  MIMIC-IV        Qwen2.5-14B-Instruct   \n",
       "30  MIMIC-IV  Mistral-Nemo-Instruct-2407   \n",
       "31       MIT  Mistral-Nemo-Instruct-2407   \n",
       "32       MIT       Llama-3.2-3B-Instruct   \n",
       "33       MIT       Llama-3.1-8B-Instruct   \n",
       "34       MIT    Mistral-7B-Instruct-v0.3   \n",
       "35       MIT        Qwen2.5-72B-Instruct   \n",
       "\n",
       "                                               Prompt  extraction_precision  \\\n",
       "14  Input Medical Note:\\n{}\\n\\nCreate a bulleted l...                 0.814   \n",
       "15  Input Medical Note:\\n{}\\n\\nCreate a bulleted l...                 0.747   \n",
       "16  Input Medical Note:\\n{}\\n\\nCreate a bulleted l...                 0.648   \n",
       "17  Input Medical Note:\\n{}\\n\\nCreate a bulleted l...                 0.653   \n",
       "18  Input Medical Note:\\n{}\\n\\nCreate a bulleted l...                 0.784   \n",
       "19  Input Medical Note:\\n{}\\n\\nCreate a bulleted l...                 0.632   \n",
       "20  Input Medical Note:\\n{}\\n\\nCreate a bulleted l...                 0.598   \n",
       "21  Input Medical Note:\\n{}\\n\\nCreate a bulleted l...                 0.516   \n",
       "22  Input Medical Note:\\n{}\\n\\nCreate a bulleted l...                 0.868   \n",
       "23  Input Medical Note:\\n{}\\n\\nCreate a bulleted l...                 0.790   \n",
       "24  Input Medical Note:\\n{}\\n\\nCreate a bulleted l...                 0.802   \n",
       "25  Input Medical Note:\\n{}\\n\\nCreate a bulleted l...                 0.634   \n",
       "26  Input Medical Note:\\n{}\\n\\nCreate a bulleted l...                 0.403   \n",
       "27  Input Medical Note:\\n{}\\n\\nCreate a bulleted l...                 0.259   \n",
       "28  Input Medical Note:\\n{}\\n\\nCreate a bulleted l...                 0.766   \n",
       "29  Input Medical Note:\\n{}\\n\\nCreate a bulleted l...                 0.646   \n",
       "30  Input Medical Note:\\n{}\\n\\nCreate a bulleted l...                 0.675   \n",
       "31  Input Medical Note:\\n{}\\n\\nCreate a bulleted l...                 0.786   \n",
       "32  Input Medical Note:\\n{}\\n\\nCreate a bulleted l...                 0.590   \n",
       "33  Input Medical Note:\\n{}\\n\\nCreate a bulleted l...                 0.840   \n",
       "34  Input Medical Note:\\n{}\\n\\nCreate a bulleted l...                 0.632   \n",
       "35  Input Medical Note:\\n{}\\n\\nCreate a bulleted l...                 0.733   \n",
       "\n",
       "    extraction_recall  conditional_accuracy  conditional_macro_f1  \\\n",
       "14              0.909                 0.901                 0.555   \n",
       "15              0.881                 0.705                 0.436   \n",
       "16              0.790                 0.748                 0.348   \n",
       "17              0.821                 0.721                 0.328   \n",
       "18              0.841                 0.811                 0.492   \n",
       "19              0.730                 0.755                 0.347   \n",
       "20              0.707                 0.737                 0.431   \n",
       "21              0.611                 0.647                 0.273   \n",
       "22              0.876                 0.603                 0.357   \n",
       "23              0.826                 0.691                 0.320   \n",
       "24              0.936                 0.631                 0.372   \n",
       "25              0.753                 0.612                 0.277   \n",
       "26              0.572                 0.418                 0.208   \n",
       "27              0.372                 0.332                 0.126   \n",
       "28              0.855                 0.836                 0.526   \n",
       "29              0.771                 0.709                 0.334   \n",
       "30              0.786                 0.712                 0.329   \n",
       "31              0.867                 0.832                 0.513   \n",
       "32              0.899                 0.693                 0.378   \n",
       "33              0.921                 0.790                 0.461   \n",
       "34              0.771                 0.648                 0.395   \n",
       "35              0.805                 0.838                 0.498   \n",
       "\n",
       "    conditional_macro_precision  conditional_macro_recall  \n",
       "14                        0.568                     0.554  \n",
       "15                        0.468                     0.428  \n",
       "16                        0.362                     0.343  \n",
       "17                        0.350                     0.322  \n",
       "18                        0.507                     0.488  \n",
       "19                        0.359                     0.342  \n",
       "20                        0.439                     0.431  \n",
       "21                        0.281                     0.271  \n",
       "22                        0.381                     0.358  \n",
       "23                        0.348                     0.312  \n",
       "24                        0.380                     0.395  \n",
       "25                        0.291                     0.280  \n",
       "26                        0.201                     0.239  \n",
       "27                        0.124                     0.139  \n",
       "28                        0.541                     0.522  \n",
       "29                        0.351                     0.328  \n",
       "30                        0.351                     0.320  \n",
       "31                        0.531                     0.506  \n",
       "32                        0.383                     0.401  \n",
       "33                        0.461                     0.482  \n",
       "34                        0.429                     0.386  \n",
       "35                        0.508                     0.495  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_folder = \"/PHShome/cs1839/capstone_data/\"\n",
    "# results table path\n",
    "results_df_path = data_folder + \"results.csv\"\n",
    "\n",
    "result_df = pd.read_csv(results_df_path)\n",
    "# get dataset == internal data\n",
    "result_df[result_df['Dataset'] != 'Internal Data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>extraction_precision</th>\n",
       "      <th>extraction_recall</th>\n",
       "      <th>conditional_accuracy</th>\n",
       "      <th>conditional_macro_f1</th>\n",
       "      <th>conditional_macro_precision</th>\n",
       "      <th>conditional_macro_recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prompt</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Create a bulleted list of which medications are mentioned and whether they are active, discontinued, or neither.</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIT</th>\n",
       "      <th>GPT-3 + R(8 LOC)(1-Shot)</th>\n",
       "      <td>0.900</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.620</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPT-3 + R(32 LOC)(0-Shot)</th>\n",
       "      <td>0.870</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.690</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"22\" valign=\"top\">Input Medical Note:\\n{}\\n\\nCreate a bulleted list of which medications are mentioned and whether they are active, discontinued, or neither.\\n\\nExpected Output Format:\\n- Current Medications (Active): Medication_1, Medication_2\\n- Discontinued Medications: Medication_3, Medication_4\\n- Other Mentioned Medications (neither active nor discontinued): Medication_5, Medication_6\\nEND\\n\\nOutput:\\n</th>\n",
       "      <th rowspan=\"13\" valign=\"top\">MIT</th>\n",
       "      <th>meditron-70b</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.631</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.1-8B-Instruct</th>\n",
       "      <td>0.840</td>\n",
       "      <td>0.921</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.1-70B-Instruct</th>\n",
       "      <td>0.814</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.2-3B-Instruct</th>\n",
       "      <td>0.590</td>\n",
       "      <td>0.899</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen2-7B-Instruct</th>\n",
       "      <td>0.747</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.1-8B</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-Nemo-Instruct-2407</th>\n",
       "      <td>0.786</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen2.5-14B-Instruct</th>\n",
       "      <td>0.766</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.541</td>\n",
       "      <td>0.522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen2.5-32B-Instruct</th>\n",
       "      <td>0.784</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.492</td>\n",
       "      <td>0.507</td>\n",
       "      <td>0.488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen2.5-72B-Instruct</th>\n",
       "      <td>0.733</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.3</th>\n",
       "      <td>0.632</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen2-72B-Instruct</th>\n",
       "      <td>0.598</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.431</td>\n",
       "      <td>0.439</td>\n",
       "      <td>0.431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.2-1B-Instruct</th>\n",
       "      <td>0.403</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">MIMIC-IV</th>\n",
       "      <th>Llama-3.1-8B</th>\n",
       "      <td>0.790</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.691</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen2-7B-Instruct</th>\n",
       "      <td>0.653</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.721</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.1-70B-Instruct</th>\n",
       "      <td>0.648</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-Nemo-Instruct-2407</th>\n",
       "      <td>0.675</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen2.5-14B-Instruct</th>\n",
       "      <td>0.646</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meditron-70b</th>\n",
       "      <td>0.634</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.612</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen2.5-32B-Instruct</th>\n",
       "      <td>0.632</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen2-72B-Instruct</th>\n",
       "      <td>0.516</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.647</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.2-1B-Instruct</th>\n",
       "      <td>0.259</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                        extraction_precision  \\\n",
       "Prompt                                             Dataset  Model                                              \n",
       "Create a bulleted list of which medications are... MIT      GPT-3 + R(8 LOC)(1-Shot)                   0.900   \n",
       "                                                            GPT-3 + R(32 LOC)(0-Shot)                  0.870   \n",
       "Input Medical Note:\\n{}\\n\\nCreate a bulleted li... MIT      meditron-70b                               0.802   \n",
       "                                                            Llama-3.1-8B-Instruct                      0.840   \n",
       "                                                            Llama-3.1-70B-Instruct                     0.814   \n",
       "                                                            Llama-3.2-3B-Instruct                      0.590   \n",
       "                                                            Qwen2-7B-Instruct                          0.747   \n",
       "                                                            Llama-3.1-8B                               0.868   \n",
       "                                                            Mistral-Nemo-Instruct-2407                 0.786   \n",
       "                                                            Qwen2.5-14B-Instruct                       0.766   \n",
       "                                                            Qwen2.5-32B-Instruct                       0.784   \n",
       "                                                            Qwen2.5-72B-Instruct                       0.733   \n",
       "                                                            Mistral-7B-Instruct-v0.3                   0.632   \n",
       "                                                            Qwen2-72B-Instruct                         0.598   \n",
       "                                                            Llama-3.2-1B-Instruct                      0.403   \n",
       "                                                   MIMIC-IV Llama-3.1-8B                               0.790   \n",
       "                                                            Qwen2-7B-Instruct                          0.653   \n",
       "                                                            Llama-3.1-70B-Instruct                     0.648   \n",
       "                                                            Mistral-Nemo-Instruct-2407                 0.675   \n",
       "                                                            Qwen2.5-14B-Instruct                       0.646   \n",
       "                                                            meditron-70b                               0.634   \n",
       "                                                            Qwen2.5-32B-Instruct                       0.632   \n",
       "                                                            Qwen2-72B-Instruct                         0.516   \n",
       "                                                            Llama-3.2-1B-Instruct                      0.259   \n",
       "\n",
       "                                                                                        extraction_recall  \\\n",
       "Prompt                                             Dataset  Model                                           \n",
       "Create a bulleted list of which medications are... MIT      GPT-3 + R(8 LOC)(1-Shot)                0.920   \n",
       "                                                            GPT-3 + R(32 LOC)(0-Shot)               0.830   \n",
       "Input Medical Note:\\n{}\\n\\nCreate a bulleted li... MIT      meditron-70b                            0.936   \n",
       "                                                            Llama-3.1-8B-Instruct                   0.921   \n",
       "                                                            Llama-3.1-70B-Instruct                  0.909   \n",
       "                                                            Llama-3.2-3B-Instruct                   0.899   \n",
       "                                                            Qwen2-7B-Instruct                       0.881   \n",
       "                                                            Llama-3.1-8B                            0.876   \n",
       "                                                            Mistral-Nemo-Instruct-2407              0.867   \n",
       "                                                            Qwen2.5-14B-Instruct                    0.855   \n",
       "                                                            Qwen2.5-32B-Instruct                    0.841   \n",
       "                                                            Qwen2.5-72B-Instruct                    0.805   \n",
       "                                                            Mistral-7B-Instruct-v0.3                0.771   \n",
       "                                                            Qwen2-72B-Instruct                      0.707   \n",
       "                                                            Llama-3.2-1B-Instruct                   0.572   \n",
       "                                                   MIMIC-IV Llama-3.1-8B                            0.826   \n",
       "                                                            Qwen2-7B-Instruct                       0.821   \n",
       "                                                            Llama-3.1-70B-Instruct                  0.790   \n",
       "                                                            Mistral-Nemo-Instruct-2407              0.786   \n",
       "                                                            Qwen2.5-14B-Instruct                    0.771   \n",
       "                                                            meditron-70b                            0.753   \n",
       "                                                            Qwen2.5-32B-Instruct                    0.730   \n",
       "                                                            Qwen2-72B-Instruct                      0.611   \n",
       "                                                            Llama-3.2-1B-Instruct                   0.372   \n",
       "\n",
       "                                                                                        conditional_accuracy  \\\n",
       "Prompt                                             Dataset  Model                                              \n",
       "Create a bulleted list of which medications are... MIT      GPT-3 + R(8 LOC)(1-Shot)                   0.890   \n",
       "                                                            GPT-3 + R(32 LOC)(0-Shot)                  0.850   \n",
       "Input Medical Note:\\n{}\\n\\nCreate a bulleted li... MIT      meditron-70b                               0.631   \n",
       "                                                            Llama-3.1-8B-Instruct                      0.790   \n",
       "                                                            Llama-3.1-70B-Instruct                     0.901   \n",
       "                                                            Llama-3.2-3B-Instruct                      0.693   \n",
       "                                                            Qwen2-7B-Instruct                          0.705   \n",
       "                                                            Llama-3.1-8B                               0.603   \n",
       "                                                            Mistral-Nemo-Instruct-2407                 0.832   \n",
       "                                                            Qwen2.5-14B-Instruct                       0.836   \n",
       "                                                            Qwen2.5-32B-Instruct                       0.811   \n",
       "                                                            Qwen2.5-72B-Instruct                       0.838   \n",
       "                                                            Mistral-7B-Instruct-v0.3                   0.648   \n",
       "                                                            Qwen2-72B-Instruct                         0.737   \n",
       "                                                            Llama-3.2-1B-Instruct                      0.418   \n",
       "                                                   MIMIC-IV Llama-3.1-8B                               0.691   \n",
       "                                                            Qwen2-7B-Instruct                          0.721   \n",
       "                                                            Llama-3.1-70B-Instruct                     0.748   \n",
       "                                                            Mistral-Nemo-Instruct-2407                 0.712   \n",
       "                                                            Qwen2.5-14B-Instruct                       0.709   \n",
       "                                                            meditron-70b                               0.612   \n",
       "                                                            Qwen2.5-32B-Instruct                       0.755   \n",
       "                                                            Qwen2-72B-Instruct                         0.647   \n",
       "                                                            Llama-3.2-1B-Instruct                      0.332   \n",
       "\n",
       "                                                                                        conditional_macro_f1  \\\n",
       "Prompt                                             Dataset  Model                                              \n",
       "Create a bulleted list of which medications are... MIT      GPT-3 + R(8 LOC)(1-Shot)                   0.620   \n",
       "                                                            GPT-3 + R(32 LOC)(0-Shot)                  0.690   \n",
       "Input Medical Note:\\n{}\\n\\nCreate a bulleted li... MIT      meditron-70b                               0.372   \n",
       "                                                            Llama-3.1-8B-Instruct                      0.461   \n",
       "                                                            Llama-3.1-70B-Instruct                     0.555   \n",
       "                                                            Llama-3.2-3B-Instruct                      0.378   \n",
       "                                                            Qwen2-7B-Instruct                          0.436   \n",
       "                                                            Llama-3.1-8B                               0.357   \n",
       "                                                            Mistral-Nemo-Instruct-2407                 0.513   \n",
       "                                                            Qwen2.5-14B-Instruct                       0.526   \n",
       "                                                            Qwen2.5-32B-Instruct                       0.492   \n",
       "                                                            Qwen2.5-72B-Instruct                       0.498   \n",
       "                                                            Mistral-7B-Instruct-v0.3                   0.395   \n",
       "                                                            Qwen2-72B-Instruct                         0.431   \n",
       "                                                            Llama-3.2-1B-Instruct                      0.208   \n",
       "                                                   MIMIC-IV Llama-3.1-8B                               0.320   \n",
       "                                                            Qwen2-7B-Instruct                          0.328   \n",
       "                                                            Llama-3.1-70B-Instruct                     0.348   \n",
       "                                                            Mistral-Nemo-Instruct-2407                 0.329   \n",
       "                                                            Qwen2.5-14B-Instruct                       0.334   \n",
       "                                                            meditron-70b                               0.277   \n",
       "                                                            Qwen2.5-32B-Instruct                       0.347   \n",
       "                                                            Qwen2-72B-Instruct                         0.273   \n",
       "                                                            Llama-3.2-1B-Instruct                      0.126   \n",
       "\n",
       "                                                                                       conditional_macro_precision  \\\n",
       "Prompt                                             Dataset  Model                                                    \n",
       "Create a bulleted list of which medications are... MIT      GPT-3 + R(8 LOC)(1-Shot)                            --   \n",
       "                                                            GPT-3 + R(32 LOC)(0-Shot)                           --   \n",
       "Input Medical Note:\\n{}\\n\\nCreate a bulleted li... MIT      meditron-70b                                      0.38   \n",
       "                                                            Llama-3.1-8B-Instruct                            0.461   \n",
       "                                                            Llama-3.1-70B-Instruct                           0.568   \n",
       "                                                            Llama-3.2-3B-Instruct                            0.383   \n",
       "                                                            Qwen2-7B-Instruct                                0.468   \n",
       "                                                            Llama-3.1-8B                                     0.381   \n",
       "                                                            Mistral-Nemo-Instruct-2407                       0.531   \n",
       "                                                            Qwen2.5-14B-Instruct                             0.541   \n",
       "                                                            Qwen2.5-32B-Instruct                             0.507   \n",
       "                                                            Qwen2.5-72B-Instruct                             0.508   \n",
       "                                                            Mistral-7B-Instruct-v0.3                         0.429   \n",
       "                                                            Qwen2-72B-Instruct                               0.439   \n",
       "                                                            Llama-3.2-1B-Instruct                            0.201   \n",
       "                                                   MIMIC-IV Llama-3.1-8B                                     0.348   \n",
       "                                                            Qwen2-7B-Instruct                                 0.35   \n",
       "                                                            Llama-3.1-70B-Instruct                           0.362   \n",
       "                                                            Mistral-Nemo-Instruct-2407                       0.351   \n",
       "                                                            Qwen2.5-14B-Instruct                             0.351   \n",
       "                                                            meditron-70b                                     0.291   \n",
       "                                                            Qwen2.5-32B-Instruct                             0.359   \n",
       "                                                            Qwen2-72B-Instruct                               0.281   \n",
       "                                                            Llama-3.2-1B-Instruct                            0.124   \n",
       "\n",
       "                                                                                       conditional_macro_recall  \n",
       "Prompt                                             Dataset  Model                                                \n",
       "Create a bulleted list of which medications are... MIT      GPT-3 + R(8 LOC)(1-Shot)                         --  \n",
       "                                                            GPT-3 + R(32 LOC)(0-Shot)                        --  \n",
       "Input Medical Note:\\n{}\\n\\nCreate a bulleted li... MIT      meditron-70b                                  0.395  \n",
       "                                                            Llama-3.1-8B-Instruct                         0.482  \n",
       "                                                            Llama-3.1-70B-Instruct                        0.554  \n",
       "                                                            Llama-3.2-3B-Instruct                         0.401  \n",
       "                                                            Qwen2-7B-Instruct                             0.428  \n",
       "                                                            Llama-3.1-8B                                  0.358  \n",
       "                                                            Mistral-Nemo-Instruct-2407                    0.506  \n",
       "                                                            Qwen2.5-14B-Instruct                          0.522  \n",
       "                                                            Qwen2.5-32B-Instruct                          0.488  \n",
       "                                                            Qwen2.5-72B-Instruct                          0.495  \n",
       "                                                            Mistral-7B-Instruct-v0.3                      0.386  \n",
       "                                                            Qwen2-72B-Instruct                            0.431  \n",
       "                                                            Llama-3.2-1B-Instruct                         0.239  \n",
       "                                                   MIMIC-IV Llama-3.1-8B                                  0.312  \n",
       "                                                            Qwen2-7B-Instruct                             0.322  \n",
       "                                                            Llama-3.1-70B-Instruct                        0.343  \n",
       "                                                            Mistral-Nemo-Instruct-2407                     0.32  \n",
       "                                                            Qwen2.5-14B-Instruct                          0.328  \n",
       "                                                            meditron-70b                                   0.28  \n",
       "                                                            Qwen2.5-32B-Instruct                          0.342  \n",
       "                                                            Qwen2-72B-Instruct                            0.271  \n",
       "                                                            Llama-3.2-1B-Instruct                         0.139  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data and sort it by the specified columns\n",
    "import pandas as pd\n",
    "\n",
    "# Data folder\n",
    "data_folder = \"/PHShome/cs1839/capstone_data/\"\n",
    "# results table path\n",
    "results_df_path = data_folder + \"results.csv\"\n",
    "\n",
    "result_df = pd.read_csv(results_df_path).round(3)\n",
    "\n",
    "result_df = result_df._append({'Prompt': 'Create a bulleted list of which medications are mentioned and whether they are active, discontinued, or neither.',\n",
    "                   'Dataset': 'MIT', \n",
    "                   'Model': 'GPT-3 + R(32 LOC)(0-Shot)',\n",
    "                   'extraction_precision': 0.87,\n",
    "                   'extraction_recall': 0.83,\n",
    "                   'conditional_accuracy': 0.85,\n",
    "                   'conditional_macro_f1': 0.69,\n",
    "                   'conditional_macro_precision': '--',\n",
    "                   'conditional_macro_recall': '--'}, ignore_index=True)\n",
    "\n",
    "\n",
    "result_df = result_df._append({'Prompt': 'Create a bulleted list of which medications are mentioned and whether they are active, discontinued, or neither.',\n",
    "                   'Dataset': 'MIT', \n",
    "                   'Model': 'GPT-3 + R(8 LOC)(1-Shot)',\n",
    "                   'extraction_precision': 0.90,\n",
    "                   'extraction_recall': 0.92,\n",
    "                   'conditional_accuracy': 0.89,\n",
    "                   'conditional_macro_f1': 0.62,\n",
    "                   'conditional_macro_precision': '--',\n",
    "                   'conditional_macro_recall': '--'}, ignore_index=True)\n",
    "\n",
    "result_df[result_df.Dataset != 'Internal Data'].\\\n",
    "sort_values(\n",
    "    by=['Prompt', 'Dataset', 'extraction_recall', 'conditional_accuracy', 'conditional_macro_f1'],\n",
    "    ascending=[True, False, False, False, False] \n",
    ").set_index(['Prompt', 'Dataset', 'Model'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>extraction_precision</th>\n",
       "      <th>extraction_recall</th>\n",
       "      <th>conditional_accuracy</th>\n",
       "      <th>conditional_macro_f1</th>\n",
       "      <th>conditional_macro_precision</th>\n",
       "      <th>conditional_macro_recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prompt</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"14\" valign=\"top\">Input Medical Note:\\n{}\\n\\nCreate a bulleted list of which medications are mentioned and whether they are active, discontinued. This dataset will only be evaluated on the following medications: 'prochlorperazine', 'compazine', 'navane', 'fluphenazine', 'haldol', 'haloperidol', 'pimozide', 'STELAZINE', 'THORAZINE', 'prolixin', 'perphenazine', 'sertraline', 'memantine', 'chlorproMAZINE', 'loxapine'.\\n\\nExpected Output Format:\\n- Current Medications (Active): Medication_1, Medication_2\\n- Discontinued Medications: Medication_3, Medication_4\\nEND\\n\\nOutput:\\n</th>\n",
       "      <th rowspan=\"14\" valign=\"top\">Internal Data</th>\n",
       "      <th>Qwen2.5-14B-Instruct</th>\n",
       "      <td>0.498</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meditron-70b</th>\n",
       "      <td>0.343</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-Nemo-Instruct-2407</th>\n",
       "      <td>0.595</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.1-70B-Instruct</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.396</td>\n",
       "      <td>0.460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.1-8B</th>\n",
       "      <td>0.377</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.2-3B-Instruct</th>\n",
       "      <td>0.269</td>\n",
       "      <td>0.641</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen2.5-32B-Instruct</th>\n",
       "      <td>0.603</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.337</td>\n",
       "      <td>0.312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen2-7B-Instruct</th>\n",
       "      <td>0.339</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen2.5-72B-Instruct</th>\n",
       "      <td>0.823</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.3</th>\n",
       "      <td>0.315</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.1-8B-Instruct</th>\n",
       "      <td>0.362</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.607</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen2-72B-Instruct</th>\n",
       "      <td>0.238</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meditron-7b</th>\n",
       "      <td>0.069</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.2-1B-Instruct</th>\n",
       "      <td>0.025</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                             extraction_precision  \\\n",
       "Prompt                                             Dataset       Model                                              \n",
       "Input Medical Note:\\n{}\\n\\nCreate a bulleted li... Internal Data Qwen2.5-14B-Instruct                       0.498   \n",
       "                                                                 meditron-70b                               0.343   \n",
       "                                                                 Mistral-Nemo-Instruct-2407                 0.595   \n",
       "                                                                 Llama-3.1-70B-Instruct                     0.798   \n",
       "                                                                 Llama-3.1-8B                               0.377   \n",
       "                                                                 Llama-3.2-3B-Instruct                      0.269   \n",
       "                                                                 Qwen2.5-32B-Instruct                       0.603   \n",
       "                                                                 Qwen2-7B-Instruct                          0.339   \n",
       "                                                                 Qwen2.5-72B-Instruct                       0.823   \n",
       "                                                                 Mistral-7B-Instruct-v0.3                   0.315   \n",
       "                                                                 Llama-3.1-8B-Instruct                      0.362   \n",
       "                                                                 Qwen2-72B-Instruct                         0.238   \n",
       "                                                                 meditron-7b                                0.069   \n",
       "                                                                 Llama-3.2-1B-Instruct                      0.025   \n",
       "\n",
       "                                                                                             extraction_recall  \\\n",
       "Prompt                                             Dataset       Model                                           \n",
       "Input Medical Note:\\n{}\\n\\nCreate a bulleted li... Internal Data Qwen2.5-14B-Instruct                    0.867   \n",
       "                                                                 meditron-70b                            0.754   \n",
       "                                                                 Mistral-Nemo-Instruct-2407              0.724   \n",
       "                                                                 Llama-3.1-70B-Instruct                  0.702   \n",
       "                                                                 Llama-3.1-8B                            0.686   \n",
       "                                                                 Llama-3.2-3B-Instruct                   0.641   \n",
       "                                                                 Qwen2.5-32B-Instruct                    0.598   \n",
       "                                                                 Qwen2-7B-Instruct                       0.594   \n",
       "                                                                 Qwen2.5-72B-Instruct                    0.588   \n",
       "                                                                 Mistral-7B-Instruct-v0.3                0.495   \n",
       "                                                                 Llama-3.1-8B-Instruct                   0.448   \n",
       "                                                                 Qwen2-72B-Instruct                      0.264   \n",
       "                                                                 meditron-7b                             0.184   \n",
       "                                                                 Llama-3.2-1B-Instruct                   0.088   \n",
       "\n",
       "                                                                                             conditional_accuracy  \\\n",
       "Prompt                                             Dataset       Model                                              \n",
       "Input Medical Note:\\n{}\\n\\nCreate a bulleted li... Internal Data Qwen2.5-14B-Instruct                       0.979   \n",
       "                                                                 meditron-70b                               0.863   \n",
       "                                                                 Mistral-Nemo-Instruct-2407                 0.863   \n",
       "                                                                 Llama-3.1-70B-Instruct                     0.986   \n",
       "                                                                 Llama-3.1-8B                               0.926   \n",
       "                                                                 Llama-3.2-3B-Instruct                      0.884   \n",
       "                                                                 Qwen2.5-32B-Instruct                       0.744   \n",
       "                                                                 Qwen2-7B-Instruct                          0.789   \n",
       "                                                                 Qwen2.5-72B-Instruct                       0.842   \n",
       "                                                                 Mistral-7B-Instruct-v0.3                   0.733   \n",
       "                                                                 Llama-3.1-8B-Instruct                      0.607   \n",
       "                                                                 Qwen2-72B-Instruct                         0.316   \n",
       "                                                                 meditron-7b                                0.186   \n",
       "                                                                 Llama-3.2-1B-Instruct                      0.109   \n",
       "\n",
       "                                                                                             conditional_macro_f1  \\\n",
       "Prompt                                             Dataset       Model                                              \n",
       "Input Medical Note:\\n{}\\n\\nCreate a bulleted li... Internal Data Qwen2.5-14B-Instruct                       0.364   \n",
       "                                                                 meditron-70b                               0.258   \n",
       "                                                                 Mistral-Nemo-Instruct-2407                 0.298   \n",
       "                                                                 Llama-3.1-70B-Instruct                     0.412   \n",
       "                                                                 Llama-3.1-8B                               0.221   \n",
       "                                                                 Llama-3.2-3B-Instruct                      0.209   \n",
       "                                                                 Qwen2.5-32B-Instruct                       0.315   \n",
       "                                                                 Qwen2-7B-Instruct                          0.208   \n",
       "                                                                 Qwen2.5-72B-Instruct                       0.387   \n",
       "                                                                 Mistral-7B-Instruct-v0.3                   0.235   \n",
       "                                                                 Llama-3.1-8B-Instruct                      0.193   \n",
       "                                                                 Qwen2-72B-Instruct                         0.138   \n",
       "                                                                 meditron-7b                                0.074   \n",
       "                                                                 Llama-3.2-1B-Instruct                      0.009   \n",
       "\n",
       "                                                                                             conditional_macro_precision  \\\n",
       "Prompt                                             Dataset       Model                                                     \n",
       "Input Medical Note:\\n{}\\n\\nCreate a bulleted li... Internal Data Qwen2.5-14B-Instruct                              0.364   \n",
       "                                                                 meditron-70b                                      0.241   \n",
       "                                                                 Mistral-Nemo-Instruct-2407                        0.274   \n",
       "                                                                 Llama-3.1-70B-Instruct                            0.396   \n",
       "                                                                 Llama-3.1-8B                                      0.188   \n",
       "                                                                 Llama-3.2-3B-Instruct                             0.174   \n",
       "                                                                 Qwen2.5-32B-Instruct                              0.337   \n",
       "                                                                 Qwen2-7B-Instruct                                 0.180   \n",
       "                                                                 Qwen2.5-72B-Instruct                              0.389   \n",
       "                                                                 Mistral-7B-Instruct-v0.3                          0.219   \n",
       "                                                                 Llama-3.1-8B-Instruct                             0.183   \n",
       "                                                                 Qwen2-72B-Instruct                                0.133   \n",
       "                                                                 meditron-7b                                       0.075   \n",
       "                                                                 Llama-3.2-1B-Instruct                             0.006   \n",
       "\n",
       "                                                                                             conditional_macro_recall  \n",
       "Prompt                                             Dataset       Model                                                 \n",
       "Input Medical Note:\\n{}\\n\\nCreate a bulleted li... Internal Data Qwen2.5-14B-Instruct                           0.399  \n",
       "                                                                 meditron-70b                                   0.295  \n",
       "                                                                 Mistral-Nemo-Instruct-2407                     0.361  \n",
       "                                                                 Llama-3.1-70B-Instruct                         0.460  \n",
       "                                                                 Llama-3.1-8B                                   0.317  \n",
       "                                                                 Llama-3.2-3B-Instruct                          0.301  \n",
       "                                                                 Qwen2.5-32B-Instruct                           0.312  \n",
       "                                                                 Qwen2-7B-Instruct                              0.312  \n",
       "                                                                 Qwen2.5-72B-Instruct                           0.387  \n",
       "                                                                 Mistral-7B-Instruct-v0.3                       0.296  \n",
       "                                                                 Llama-3.1-8B-Instruct                          0.248  \n",
       "                                                                 Qwen2-72B-Instruct                             0.152  \n",
       "                                                                 meditron-7b                                    0.074  \n",
       "                                                                 Llama-3.2-1B-Instruct                          0.029  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df[result_df.Dataset != 'Internal Data'].\\\n",
    "sort_values(\n",
    "    by=['Prompt', 'Dataset', 'extraction_recall', 'conditional_accuracy', 'conditional_macro_f1'],\n",
    "    ascending=[True, False, False, False, False] \n",
    ").set_index(['Prompt', 'Dataset', 'Model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lovenox', 'aspirin', 'Coumadin']\n",
      "['Lopressor', 'Lasix', 'spironolactone', 'metoprolol', 'glyburide']\n",
      "['Lovenox', 'aspirin', 'Coumadin']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "response = \"\"\"- Current Medications (Active): Lovenox, aspirin, Coumadin\n",
    "- Discontinued Medications: Lopressor, Lasix, spironolactone, metoprolol, glyburide\n",
    "- Other Mentioned Medications (neither active nor discontinued): Lovenox, aspirin, Coumadin\"\"\"\n",
    "\n",
    "active_medications = re.search(r'Current Medications \\(Active\\):\\s*(.*?)(?:\\n- Discontinued Medications:)', response, re.IGNORECASE)\n",
    "discontinued_medications = re.search(r'Discontinued Medications:\\s*(.*?)(?:\\n- Other Mentioned Medications)', response, re.IGNORECASE)\n",
    "neither_medications = re.search(r\"Other Mentioned Medications \\(neither active nor discontinued\\): (.*?)(?:\\s*END|\\n|$)\", response, re.IGNORECASE | re.DOTALL)\n",
    "\n",
    "\n",
    "# Convert to lists and handle None cases\n",
    "active_medications = active_medications.group(1).split(', ') if active_medications and active_medications.group(1).strip().lower() not in ['none',''] else []\n",
    "discontinued_medications = discontinued_medications.group(1).split(', ') if discontinued_medications and discontinued_medications.group(1).strip().lower() not in ['none',''] else []\n",
    "neither_medications = neither_medications.group(1).split(', ') if neither_medications and neither_medications.group(1).strip().lower() not in ['none',''] else []\n",
    "\n",
    "print(active_medications)\n",
    "print(discontinued_medications)\n",
    "print(neither_medications)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
