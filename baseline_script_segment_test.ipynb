{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to /PHShome/cs1839/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\"\n",
    "import json\n",
    "from huggingface_hub import login\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from baseline import *\n",
    "\n",
    "# Read the JSON config file\n",
    "with open('config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Get the token from the JSON file\n",
    "hg_token = config['HuggingFace']['token']\n",
    "# Login using the token\n",
    "login(token=hg_token)\n",
    "\n",
    "# LLM folder\n",
    "llm_folder = \"/PHShome/jn180/llm_public_host\"\n",
    "# Data folder\n",
    "data_folder = \"/PHShome/cs1839/capstone_data/\"\n",
    "# results table path\n",
    "results_df_path = data_folder + \"results.csv\"\n",
    "\n",
    "# data to inference \n",
    "medication_status_test = pd.read_csv(data_folder + \"medication_status_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  1.95it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.07s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>snippet</th>\n",
       "      <th>active_medications</th>\n",
       "      <th>discontinued_medications</th>\n",
       "      <th>neither_medications</th>\n",
       "      <th>active_medications_pred</th>\n",
       "      <th>discontinued_medications_pred</th>\n",
       "      <th>neither_medications_pred</th>\n",
       "      <th>extraction_precision</th>\n",
       "      <th>extraction_recall</th>\n",
       "      <th>conditional_accuracy</th>\n",
       "      <th>conditional_macro_f1</th>\n",
       "      <th>conditional_macro_precision</th>\n",
       "      <th>conditional_macro_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>96</td>\n",
       "      <td>She did have a capsule study done during her p...</td>\n",
       "      <td>[imuran, remicade]</td>\n",
       "      <td>[6 mp]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[iv imuran]</td>\n",
       "      <td>[6 mp]</td>\n",
       "      <td>[remicade, capsule study]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                            snippet  \\\n",
       "0     96  She did have a capsule study done during her p...   \n",
       "\n",
       "   active_medications discontinued_medications neither_medications  \\\n",
       "0  [imuran, remicade]                   [6 mp]                  []   \n",
       "\n",
       "  active_medications_pred discontinued_medications_pred  \\\n",
       "0             [iv imuran]                        [6 mp]   \n",
       "\n",
       "    neither_medications_pred  extraction_precision  extraction_recall  \\\n",
       "0  [remicade, capsule study]                   0.5           0.666667   \n",
       "\n",
       "   conditional_accuracy  conditional_macro_f1  conditional_macro_precision  \\\n",
       "0                   0.5              0.333333                     0.333333   \n",
       "\n",
       "   conditional_macro_recall  \n",
       "0                  0.333333  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_model_paths ={   \n",
    "    # \"Bio_ClinicalBERT\": \"/PHShome/jn180/llm_public_host/Bio_ClinicalBERT\",\n",
    "\n",
    "    # \"Llama-3.1-8B\": \"/netapp3/raw_data3/share/llm_public_host/Llama-3.1-8B\",\n",
    "    \"Llama-3.1-8B-Instruct\": \"/netapp3/raw_data3/share/llm_public_host/Llama-3.1-8B-Instruct\",\n",
    "\n",
    "    \"Llama-3.2-1B-Instruct\": \"/netapp3/raw_data3/share/llm_public_host/Llama-3.2-1B-Instruct\",\n",
    "    \"Llama-3.2-3B-Instruct\": \"/netapp3/raw_data3/share/llm_public_host/Llama-3.2-3B-Instruct\",\n",
    "\n",
    "    \"Qwen2-7B-Instruct\": \"/PHShome/jn180/llm_public_host/Qwen2-7B-Instruct\",\n",
    "    \"Qwen2.5-14B-Instruct\": \"/netapp3/raw_data3/share/llm_public_host/Qwen2.5-14B-Instruct\",\n",
    "\n",
    "    \"meditron-7b\": \"/PHShome/jn180/llm_public_host/meditron-7b\",\n",
    "\n",
    "    # \"Mistral-7B-Instruct-v0.3\": \"/netapp3/raw_data3/share/llm_public_host/Mistral-7B-Instruct-v0.3\"\n",
    "\n",
    "}\n",
    "\n",
    "import os\n",
    "# Set the environment variable to specify the GPUs\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "\n",
    "name_dataset = \"MIT\"\n",
    "data_folder = \"/PHShome/cs1839/capstone_data/\"\n",
    "results_df_path = data_folder + \"results.csv\"\n",
    "medication_status_test = pd.read_csv(data_folder + \"medication_status_test.csv\")\n",
    "\n",
    "# prompt_template = \"\"\"\n",
    "# Identify and categorize the medications mentioned in the following medical note. Extract all medications the patient has taken before, is currently taking, and any other medications mentioned.\n",
    "# Note: Adjust the number of medications in each category based on the input. Write None if no other medication mentioned. Strictly follow the output format.\n",
    "# Expected Output Format:\n",
    "# \"\n",
    "# - Current Medications (Active): Medication_1, Medication_2\n",
    "# - Discontinued Medications: Medication_3, Medication_4\n",
    "# - Other Mentioned Medications (neither active nor discontinued): Medication_5, Medication_6\n",
    "# END\"\n",
    "\n",
    "# Input Medical Note:\n",
    "# {}\n",
    "\n",
    "# Output:\n",
    "# \"\"\"\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "Input Medical Note:\n",
    "{}\n",
    "\n",
    "Create a bulleted list of which medications are mentioned and whether they are active, discontinued, or neither.\n",
    "\n",
    "Expected Output Format:\n",
    "\"\n",
    "- Current Medications (Active): Medication_1, Medication_2\n",
    "- Discontinued Medications: Medication_3, Medication_4\n",
    "- Other Mentioned Medications (neither active nor discontinued): Medication_5, Medication_6\n",
    "END\"\n",
    "\n",
    "Output:\n",
    "\"\"\"\n",
    "\n",
    "for model_name, model_path in name_model_paths.items():\n",
    "    df = run_pipeline(model_path=model_path,\n",
    "                        input_df=medication_status_test[medication_status_test['index']==96],\n",
    "                        prompt_template=prompt_template,\n",
    "                        batch_size=16,\n",
    "                        max_token_output=80,\n",
    "                        use_sampling=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics\n",
    "\n",
    "## Task 1: Medication Extraction\n",
    "\n",
    "- **Precision**: Measures the proportion of correctly predicted medications out of all predicted medications.\n",
    "\n",
    "$$\n",
    "  \\text{Precision} = \\frac{\\text{True Positives (TP)}}{\\text{True Positives (TP)} + \\text{False Positives (FP)}}\n",
    "  $$\n",
    "\n",
    "- **Recall**: Measures the proportion of correctly predicted medications out of all actual medications.\n",
    "\n",
    " $$\n",
    "  \\text{Recall} = \\frac{\\text{True Positives (TP)}}{\\text{True Positives (TP)} + \\text{False Negatives (FN)}}\n",
    "  $$\n",
    "\n",
    "## Task 2: Status Classification\n",
    "\n",
    "- **Conditional Accuracy**: Measures the proportion of correct status predictions out of all correctly extracted medications from Task 1.\n",
    "  $$\n",
    "  \\text{Conditional Accuracy} = \\frac{\\text{Correct Predictions for the Classes}}{\\text{Total Correctly Extracted Medications from Task 1}}\n",
    "  $$\n",
    "\n",
    "- **Conditional Macro F1**: Combines precision and recall for each status class, calculates the F1-score for each, then averages them across classes.\n",
    "  $$\n",
    "  \\text{F1\\text{-}score} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
    "  $$\n",
    "\n",
    "---\n",
    "\n",
    "# Example\n",
    "## Task 1\n",
    "\n",
    "| Active Medication | Discontinued Medication | Active Medication (Predicted) | Discontinued Medication (Predicted) |\n",
    "|-------------------|-------------------------|-------------------------------|-------------------------------------|\n",
    "| A                 | B                       | A                             | C                                   |\n",
    "\n",
    "\n",
    "True Set: A, B\n",
    "\n",
    "Pred Set: A, C\n",
    "\n",
    "\n",
    "\n",
    "Precision = 1/2\n",
    "\n",
    "Recall = 1/2\n",
    "\n",
    "\n",
    "## Task 2\n",
    "conditional metrics will only consider: A (C is not correctly extracted, removed)\n",
    "| Active Medication | Discontinued Medication | Active Medication (Predicted) | Discontinued Medication (Predicted) |\n",
    "|-------------------|-------------------------|-------------------------------|-------------------------------------|\n",
    "| A                 | B                       | A                             |                                     |\n",
    "\n",
    "conditional_accuracy = 1/2 \n",
    "\n",
    "conditional_precision:\n",
    "- Active: 1\n",
    "- **Discountinued: 1**\n",
    "\n",
    "conditional_recall:\n",
    "- Active: 1\n",
    "- Discountinued: 0\n",
    "\n",
    "\n",
    "\n",
    "| Active Medication | Discontinued Medication | Active Medication (Predicted) | Discontinued Medication (Predicted) |\n",
    "|-------------------|-------------------------|-------------------------------|-------------------------------------|\n",
    "| A, C              |                         | A                             |C                                    |\n",
    "| A                 |B, C                     | A                             |C                                    |\n",
    "| A, B              |                         |                               |                                     |\n",
    "\n",
    "conditional_acc =（A+A+C）/ (A+C+A+C) = 3/4 \n",
    "\n",
    "conditional_precision_active = (A+A)/(A+A) = 1\n",
    "\n",
    "conditional_precision_discountinued = C / (C+C) = 1/2\n",
    "\n",
    "conditional_recall_active = (A+A)/ (A+A+A+B+c) = 2/5\n",
    "\n",
    "conditional_recall_discountinued = (C)/ (B+C) = 1/2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction Precision: 0.889\n",
      "Extraction Recall: 0.889\n",
      "Extraction F1: 0.889\n",
      "Conditional Accuracy: 0.556\n",
      "Conditional Macro Precision: 0.378\n",
      "Conditional Macro Recall: 0.378\n",
      "Conditional Macro F1: 0.378\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>active_medications</th>\n",
       "      <th>discontinued_medications</th>\n",
       "      <th>neither_medications</th>\n",
       "      <th>active_medications_pred</th>\n",
       "      <th>discontinued_medications_pred</th>\n",
       "      <th>neither_medications_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[A, C]</td>\n",
       "      <td>[E]</td>\n",
       "      <td>[D]</td>\n",
       "      <td>[A, E]</td>\n",
       "      <td>[C, D]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[A]</td>\n",
       "      <td>[B, C]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[A]</td>\n",
       "      <td>[C]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[A, B]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[A, B]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[E]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  active_medications discontinued_medications neither_medications  \\\n",
       "0             [A, C]                      [E]                 [D]   \n",
       "1                [A]                   [B, C]                  []   \n",
       "2             [A, B]                       []                  []   \n",
       "\n",
       "  active_medications_pred discontinued_medications_pred  \\\n",
       "0                  [A, E]                        [C, D]   \n",
       "1                     [A]                           [C]   \n",
       "2                  [A, B]                            []   \n",
       "\n",
       "  neither_medications_pred  \n",
       "0                       []  \n",
       "1                       []  \n",
       "2                      [E]  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from baseline import calculate_metrics_by_dataset\n",
    "\n",
    "# Example usage\n",
    "data = {\n",
    "    'active_medications': [['A', 'C'], ['A'], ['A', 'B']],\n",
    "    'discontinued_medications': [['E'], ['B', 'C'], []],\n",
    "    'neither_medications': [['D'], [], []],\n",
    "    'active_medications_pred': [['A','E'], ['A'], ['A','B']],\n",
    "    'discontinued_medications_pred': [['C','D'], ['C'], []],\n",
    "    'neither_medications_pred': [[], [], ['E']]\n",
    "}\n",
    "\n",
    "# Create the DataFrame\n",
    "mimic_iv = pd.DataFrame(data)\n",
    "\n",
    "# Run the function on the dataset\n",
    "extraction_precision, extraction_recall, extraction_f1, conditional_accuracy, conditional_macro_f1, conditional_macro_precision, conditional_macro_recall = calculate_metrics_by_dataset(mimic_iv, 'MIMIC')\n",
    "\n",
    "# Print the results\n",
    "print(f\"Extraction Precision: {extraction_precision:.3f}\")\n",
    "print(f\"Extraction Recall: {extraction_recall:.3f}\")\n",
    "print(f\"Extraction F1: {extraction_f1:.3f}\")\n",
    "print(f\"Conditional Accuracy: {conditional_accuracy:.3f}\")\n",
    "print(f\"Conditional Macro Precision: {conditional_macro_precision:.3f}\")\n",
    "print(f\"Conditional Macro Recall: {conditional_macro_recall:.3f}\")\n",
    "print(f\"Conditional Macro F1: {conditional_macro_f1:.3f}\")\n",
    "\n",
    "mimic_iv[['active_medications', 'discontinued_medications', 'neither_medications', 'active_medications_pred', 'discontinued_medications_pred', 'neither_medications_pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>extraction_precision</th>\n",
       "      <th>extraction_recall</th>\n",
       "      <th>extraction_f1</th>\n",
       "      <th>conditional_accuracy</th>\n",
       "      <th>conditional_macro_f1</th>\n",
       "      <th>conditional_macro_precision</th>\n",
       "      <th>conditional_macro_recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prompt</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Create a bulleted list of which medications are mentioned and whether they are active, discontinued, or neither.</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIT</th>\n",
       "      <th>GPT-3 + R(8 LOC)(1-Shot)</th>\n",
       "      <td>0.900</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.620</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPT-3 + R(32 LOC)(0-Shot)</th>\n",
       "      <td>0.870</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.690</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"28\" valign=\"top\">Input Medical Note:\\n{}\\n\\nCreate a bulleted list of which medications are mentioned and whether they are active, discontinued, or neither.\\n\\nExpected Output Format:\\n- Current Medications (Active): Medication_1, Medication_2\\n- Discontinued Medications: Medication_3, Medication_4\\n- Other Mentioned Medications (neither active nor discontinued): Medication_5, Medication_6\\nEND\\n\\nOutput:\\n</th>\n",
       "      <th rowspan=\"14\" valign=\"top\">MIT</th>\n",
       "      <th>Llama-3.1-70B-Instruct</th>\n",
       "      <td>0.788</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.1-8B-Instruct</th>\n",
       "      <td>0.784</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.729</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.1-8B</th>\n",
       "      <td>0.829</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen2.5-32B-Instruct</th>\n",
       "      <td>0.773</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meditron-70b</th>\n",
       "      <td>0.727</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.487</td>\n",
       "      <td>0.539</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-Nemo-Instruct-2407</th>\n",
       "      <td>0.753</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen2.5-14B-Instruct</th>\n",
       "      <td>0.731</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.785</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen2-7B-Instruct</th>\n",
       "      <td>0.689</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.567</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen2.5-72B-Instruct</th>\n",
       "      <td>0.712</td>\n",
       "      <td>0.785</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.3</th>\n",
       "      <td>0.613</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.643</td>\n",
       "      <td>0.508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen2-72B-Instruct</th>\n",
       "      <td>0.553</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.607</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.2-3B-Instruct</th>\n",
       "      <td>0.454</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.2-1B-Instruct</th>\n",
       "      <td>0.395</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.459</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meditron-7b</th>\n",
       "      <td>0.015</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"14\" valign=\"top\">MIMIC-IV</th>\n",
       "      <th>Llama-3.1-8B</th>\n",
       "      <td>0.710</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.459</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.1-8B-Instruct</th>\n",
       "      <td>0.612</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0.578</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-Nemo-Instruct-2407</th>\n",
       "      <td>0.614</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.1-70B-Instruct</th>\n",
       "      <td>0.601</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.671</td>\n",
       "      <td>0.484</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen2.5-14B-Instruct</th>\n",
       "      <td>0.586</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.459</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen2.5-32B-Instruct</th>\n",
       "      <td>0.600</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen2.5-72B-Instruct</th>\n",
       "      <td>0.604</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen2-7B-Instruct</th>\n",
       "      <td>0.526</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.388</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.546</td>\n",
       "      <td>0.482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meditron-70b</th>\n",
       "      <td>0.536</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.622</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.2-3B-Instruct</th>\n",
       "      <td>0.401</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.471</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen2-72B-Instruct</th>\n",
       "      <td>0.469</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.523</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.516</td>\n",
       "      <td>0.644</td>\n",
       "      <td>0.453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.3</th>\n",
       "      <td>0.409</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.477</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0.392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.2-1B-Instruct</th>\n",
       "      <td>0.310</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.379</td>\n",
       "      <td>0.185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meditron-7b</th>\n",
       "      <td>0.032</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                        extraction_precision  \\\n",
       "Prompt                                             Dataset  Model                                              \n",
       "Create a bulleted list of which medications are... MIT      GPT-3 + R(8 LOC)(1-Shot)                   0.900   \n",
       "                                                            GPT-3 + R(32 LOC)(0-Shot)                  0.870   \n",
       "Input Medical Note:\\n{}\\n\\nCreate a bulleted li... MIT      Llama-3.1-70B-Instruct                     0.788   \n",
       "                                                            Llama-3.1-8B-Instruct                      0.784   \n",
       "                                                            Llama-3.1-8B                               0.829   \n",
       "                                                            Qwen2.5-32B-Instruct                       0.773   \n",
       "                                                            meditron-70b                               0.727   \n",
       "                                                            Mistral-Nemo-Instruct-2407                 0.753   \n",
       "                                                            Qwen2.5-14B-Instruct                       0.731   \n",
       "                                                            Qwen2-7B-Instruct                          0.689   \n",
       "                                                            Qwen2.5-72B-Instruct                       0.712   \n",
       "                                                            Mistral-7B-Instruct-v0.3                   0.613   \n",
       "                                                            Qwen2-72B-Instruct                         0.553   \n",
       "                                                            Llama-3.2-3B-Instruct                      0.454   \n",
       "                                                            Llama-3.2-1B-Instruct                      0.395   \n",
       "                                                            meditron-7b                                0.015   \n",
       "                                                   MIMIC-IV Llama-3.1-8B                               0.710   \n",
       "                                                            Llama-3.1-8B-Instruct                      0.612   \n",
       "                                                            Mistral-Nemo-Instruct-2407                 0.614   \n",
       "                                                            Llama-3.1-70B-Instruct                     0.601   \n",
       "                                                            Qwen2.5-14B-Instruct                       0.586   \n",
       "                                                            Qwen2.5-32B-Instruct                       0.600   \n",
       "                                                            Qwen2.5-72B-Instruct                       0.604   \n",
       "                                                            Qwen2-7B-Instruct                          0.526   \n",
       "                                                            meditron-70b                               0.536   \n",
       "                                                            Llama-3.2-3B-Instruct                      0.401   \n",
       "                                                            Qwen2-72B-Instruct                         0.469   \n",
       "                                                            Mistral-7B-Instruct-v0.3                   0.409   \n",
       "                                                            Llama-3.2-1B-Instruct                      0.310   \n",
       "                                                            meditron-7b                                0.032   \n",
       "\n",
       "                                                                                        extraction_recall  \\\n",
       "Prompt                                             Dataset  Model                                           \n",
       "Create a bulleted list of which medications are... MIT      GPT-3 + R(8 LOC)(1-Shot)                0.920   \n",
       "                                                            GPT-3 + R(32 LOC)(0-Shot)               0.830   \n",
       "Input Medical Note:\\n{}\\n\\nCreate a bulleted li... MIT      Llama-3.1-70B-Instruct                  0.909   \n",
       "                                                            Llama-3.1-8B-Instruct                   0.909   \n",
       "                                                            Llama-3.1-8B                            0.844   \n",
       "                                                            Qwen2.5-32B-Instruct                    0.853   \n",
       "                                                            meditron-70b                            0.909   \n",
       "                                                            Mistral-Nemo-Instruct-2407              0.862   \n",
       "                                                            Qwen2.5-14B-Instruct                    0.847   \n",
       "                                                            Qwen2-7B-Instruct                       0.862   \n",
       "                                                            Qwen2.5-72B-Instruct                    0.785   \n",
       "                                                            Mistral-7B-Instruct-v0.3                0.750   \n",
       "                                                            Qwen2-72B-Instruct                      0.674   \n",
       "                                                            Llama-3.2-3B-Instruct                   0.882   \n",
       "                                                            Llama-3.2-1B-Instruct                   0.547   \n",
       "                                                            meditron-7b                             0.009   \n",
       "                                                   MIMIC-IV Llama-3.1-8B                            0.784   \n",
       "                                                            Llama-3.1-8B-Instruct                   0.832   \n",
       "                                                            Mistral-Nemo-Instruct-2407              0.744   \n",
       "                                                            Llama-3.1-70B-Instruct                  0.760   \n",
       "                                                            Qwen2.5-14B-Instruct                    0.742   \n",
       "                                                            Qwen2.5-32B-Instruct                    0.710   \n",
       "                                                            Qwen2.5-72B-Instruct                    0.701   \n",
       "                                                            Qwen2-7B-Instruct                       0.783   \n",
       "                                                            meditron-70b                            0.742   \n",
       "                                                            Llama-3.2-3B-Instruct                   0.800   \n",
       "                                                            Qwen2-72B-Instruct                      0.592   \n",
       "                                                            Mistral-7B-Instruct-v0.3                0.571   \n",
       "                                                            Llama-3.2-1B-Instruct                   0.376   \n",
       "                                                            meditron-7b                             0.046   \n",
       "\n",
       "                                                                                        extraction_f1  \\\n",
       "Prompt                                             Dataset  Model                                       \n",
       "Create a bulleted list of which medications are... MIT      GPT-3 + R(8 LOC)(1-Shot)            0.910   \n",
       "                                                            GPT-3 + R(32 LOC)(0-Shot)           0.850   \n",
       "Input Medical Note:\\n{}\\n\\nCreate a bulleted li... MIT      Llama-3.1-70B-Instruct              0.844   \n",
       "                                                            Llama-3.1-8B-Instruct               0.842   \n",
       "                                                            Llama-3.1-8B                        0.837   \n",
       "                                                            Qwen2.5-32B-Instruct                0.811   \n",
       "                                                            meditron-70b                        0.808   \n",
       "                                                            Mistral-Nemo-Instruct-2407          0.804   \n",
       "                                                            Qwen2.5-14B-Instruct                0.785   \n",
       "                                                            Qwen2-7B-Instruct                   0.766   \n",
       "                                                            Qwen2.5-72B-Instruct                0.747   \n",
       "                                                            Mistral-7B-Instruct-v0.3            0.675   \n",
       "                                                            Qwen2-72B-Instruct                  0.607   \n",
       "                                                            Llama-3.2-3B-Instruct               0.599   \n",
       "                                                            Llama-3.2-1B-Instruct               0.459   \n",
       "                                                            meditron-7b                         0.011   \n",
       "                                                   MIMIC-IV Llama-3.1-8B                        0.746   \n",
       "                                                            Llama-3.1-8B-Instruct               0.705   \n",
       "                                                            Mistral-Nemo-Instruct-2407          0.673   \n",
       "                                                            Llama-3.1-70B-Instruct              0.671   \n",
       "                                                            Qwen2.5-14B-Instruct                0.655   \n",
       "                                                            Qwen2.5-32B-Instruct                0.650   \n",
       "                                                            Qwen2.5-72B-Instruct                0.649   \n",
       "                                                            Qwen2-7B-Instruct                   0.629   \n",
       "                                                            meditron-70b                        0.622   \n",
       "                                                            Llama-3.2-3B-Instruct               0.535   \n",
       "                                                            Qwen2-72B-Instruct                  0.523   \n",
       "                                                            Mistral-7B-Instruct-v0.3            0.477   \n",
       "                                                            Llama-3.2-1B-Instruct               0.340   \n",
       "                                                            meditron-7b                         0.038   \n",
       "\n",
       "                                                                                        conditional_accuracy  \\\n",
       "Prompt                                             Dataset  Model                                              \n",
       "Create a bulleted list of which medications are... MIT      GPT-3 + R(8 LOC)(1-Shot)                   0.890   \n",
       "                                                            GPT-3 + R(32 LOC)(0-Shot)                  0.850   \n",
       "Input Medical Note:\\n{}\\n\\nCreate a bulleted li... MIT      Llama-3.1-70B-Instruct                     0.727   \n",
       "                                                            Llama-3.1-8B-Instruct                      0.640   \n",
       "                                                            Llama-3.1-8B                               0.532   \n",
       "                                                            Qwen2.5-32B-Instruct                       0.675   \n",
       "                                                            meditron-70b                               0.487   \n",
       "                                                            Mistral-Nemo-Instruct-2407                 0.653   \n",
       "                                                            Qwen2.5-14B-Instruct                       0.652   \n",
       "                                                            Qwen2-7B-Instruct                          0.494   \n",
       "                                                            Qwen2.5-72B-Instruct                       0.659   \n",
       "                                                            Mistral-7B-Instruct-v0.3                   0.428   \n",
       "                                                            Qwen2-72B-Instruct                         0.483   \n",
       "                                                            Llama-3.2-3B-Instruct                      0.315   \n",
       "                                                            Llama-3.2-1B-Instruct                      0.251   \n",
       "                                                            meditron-7b                                0.010   \n",
       "                                                   MIMIC-IV Llama-3.1-8B                               0.496   \n",
       "                                                            Llama-3.1-8B-Instruct                      0.483   \n",
       "                                                            Mistral-Nemo-Instruct-2407                 0.462   \n",
       "                                                            Llama-3.1-70B-Instruct                     0.484   \n",
       "                                                            Qwen2.5-14B-Instruct                       0.459   \n",
       "                                                            Qwen2.5-32B-Instruct                       0.518   \n",
       "                                                            Qwen2.5-72B-Instruct                       0.499   \n",
       "                                                            Qwen2-7B-Instruct                          0.388   \n",
       "                                                            meditron-70b                               0.385   \n",
       "                                                            Llama-3.2-3B-Instruct                      0.306   \n",
       "                                                            Qwen2-72B-Instruct                         0.378   \n",
       "                                                            Mistral-7B-Instruct-v0.3                   0.279   \n",
       "                                                            Llama-3.2-1B-Instruct                      0.213   \n",
       "                                                            meditron-7b                                0.030   \n",
       "\n",
       "                                                                                        conditional_macro_f1  \\\n",
       "Prompt                                             Dataset  Model                                              \n",
       "Create a bulleted list of which medications are... MIT      GPT-3 + R(8 LOC)(1-Shot)                   0.620   \n",
       "                                                            GPT-3 + R(32 LOC)(0-Shot)                  0.690   \n",
       "Input Medical Note:\\n{}\\n\\nCreate a bulleted li... MIT      Llama-3.1-70B-Instruct                     0.812   \n",
       "                                                            Llama-3.1-8B-Instruct                      0.729   \n",
       "                                                            Llama-3.1-8B                               0.470   \n",
       "                                                            Qwen2.5-32B-Instruct                       0.732   \n",
       "                                                            meditron-70b                               0.539   \n",
       "                                                            Mistral-Nemo-Instruct-2407                 0.699   \n",
       "                                                            Qwen2.5-14B-Instruct                       0.718   \n",
       "                                                            Qwen2-7B-Instruct                          0.567   \n",
       "                                                            Qwen2.5-72B-Instruct                       0.735   \n",
       "                                                            Mistral-7B-Instruct-v0.3                   0.540   \n",
       "                                                            Qwen2-72B-Instruct                         0.609   \n",
       "                                                            Llama-3.2-3B-Instruct                      0.522   \n",
       "                                                            Llama-3.2-1B-Instruct                      0.304   \n",
       "                                                            meditron-7b                                0.007   \n",
       "                                                   MIMIC-IV Llama-3.1-8B                               0.459   \n",
       "                                                            Llama-3.1-8B-Instruct                      0.578   \n",
       "                                                            Mistral-Nemo-Instruct-2407                 0.544   \n",
       "                                                            Llama-3.1-70B-Instruct                     0.576   \n",
       "                                                            Qwen2.5-14B-Instruct                       0.551   \n",
       "                                                            Qwen2.5-32B-Instruct                       0.657   \n",
       "                                                            Qwen2.5-72B-Instruct                       0.598   \n",
       "                                                            Qwen2-7B-Instruct                          0.502   \n",
       "                                                            meditron-70b                               0.452   \n",
       "                                                            Llama-3.2-3B-Instruct                      0.471   \n",
       "                                                            Qwen2-72B-Instruct                         0.516   \n",
       "                                                            Mistral-7B-Instruct-v0.3                   0.430   \n",
       "                                                            Llama-3.2-1B-Instruct                      0.229   \n",
       "                                                            meditron-7b                                0.060   \n",
       "\n",
       "                                                                                       conditional_macro_precision  \\\n",
       "Prompt                                             Dataset  Model                                                    \n",
       "Create a bulleted list of which medications are... MIT      GPT-3 + R(8 LOC)(1-Shot)                            --   \n",
       "                                                            GPT-3 + R(32 LOC)(0-Shot)                           --   \n",
       "Input Medical Note:\\n{}\\n\\nCreate a bulleted li... MIT      Llama-3.1-70B-Instruct                           0.846   \n",
       "                                                            Llama-3.1-8B-Instruct                            0.781   \n",
       "                                                            Llama-3.1-8B                                     0.522   \n",
       "                                                            Qwen2.5-32B-Instruct                             0.775   \n",
       "                                                            meditron-70b                                     0.581   \n",
       "                                                            Mistral-Nemo-Instruct-2407                       0.744   \n",
       "                                                            Qwen2.5-14B-Instruct                             0.776   \n",
       "                                                            Qwen2-7B-Instruct                                0.602   \n",
       "                                                            Qwen2.5-72B-Instruct                             0.833   \n",
       "                                                            Mistral-7B-Instruct-v0.3                         0.643   \n",
       "                                                            Qwen2-72B-Instruct                               0.746   \n",
       "                                                            Llama-3.2-3B-Instruct                            0.571   \n",
       "                                                            Llama-3.2-1B-Instruct                            0.435   \n",
       "                                                            meditron-7b                                      0.333   \n",
       "                                                   MIMIC-IV Llama-3.1-8B                                     0.515   \n",
       "                                                            Llama-3.1-8B-Instruct                            0.618   \n",
       "                                                            Mistral-Nemo-Instruct-2407                       0.629   \n",
       "                                                            Llama-3.1-70B-Instruct                           0.638   \n",
       "                                                            Qwen2.5-14B-Instruct                             0.616   \n",
       "                                                            Qwen2.5-32B-Instruct                             0.732   \n",
       "                                                            Qwen2.5-72B-Instruct                             0.681   \n",
       "                                                            Qwen2-7B-Instruct                                0.546   \n",
       "                                                            meditron-70b                                     0.534   \n",
       "                                                            Llama-3.2-3B-Instruct                            0.521   \n",
       "                                                            Qwen2-72B-Instruct                               0.644   \n",
       "                                                            Mistral-7B-Instruct-v0.3                         0.574   \n",
       "                                                            Llama-3.2-1B-Instruct                            0.379   \n",
       "                                                            meditron-7b                                      0.532   \n",
       "\n",
       "                                                                                       conditional_macro_recall  \n",
       "Prompt                                             Dataset  Model                                                \n",
       "Create a bulleted list of which medications are... MIT      GPT-3 + R(8 LOC)(1-Shot)                         --  \n",
       "                                                            GPT-3 + R(32 LOC)(0-Shot)                        --  \n",
       "Input Medical Note:\\n{}\\n\\nCreate a bulleted li... MIT      Llama-3.1-70B-Instruct                        0.782  \n",
       "                                                            Llama-3.1-8B-Instruct                          0.71  \n",
       "                                                            Llama-3.1-8B                                  0.434  \n",
       "                                                            Qwen2.5-32B-Instruct                          0.705  \n",
       "                                                            meditron-70b                                   0.54  \n",
       "                                                            Mistral-Nemo-Instruct-2407                    0.666  \n",
       "                                                            Qwen2.5-14B-Instruct                          0.669  \n",
       "                                                            Qwen2-7B-Instruct                             0.554  \n",
       "                                                            Qwen2.5-72B-Instruct                          0.659  \n",
       "                                                            Mistral-7B-Instruct-v0.3                      0.508  \n",
       "                                                            Qwen2-72B-Instruct                            0.517  \n",
       "                                                            Llama-3.2-3B-Instruct                         0.505  \n",
       "                                                            Llama-3.2-1B-Instruct                         0.266  \n",
       "                                                            meditron-7b                                   0.003  \n",
       "                                                   MIMIC-IV Llama-3.1-8B                                  0.428  \n",
       "                                                            Llama-3.1-8B-Instruct                         0.559  \n",
       "                                                            Mistral-Nemo-Instruct-2407                    0.543  \n",
       "                                                            Llama-3.1-70B-Instruct                        0.565  \n",
       "                                                            Qwen2.5-14B-Instruct                          0.535  \n",
       "                                                            Qwen2.5-32B-Instruct                          0.619  \n",
       "                                                            Qwen2.5-72B-Instruct                          0.576  \n",
       "                                                            Qwen2-7B-Instruct                             0.482  \n",
       "                                                            meditron-70b                                   0.41  \n",
       "                                                            Llama-3.2-3B-Instruct                         0.435  \n",
       "                                                            Qwen2-72B-Instruct                            0.453  \n",
       "                                                            Mistral-7B-Instruct-v0.3                      0.392  \n",
       "                                                            Llama-3.2-1B-Instruct                         0.185  \n",
       "                                                            meditron-7b                                   0.032  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data and sort it by the specified columns\n",
    "import pandas as pd\n",
    "\n",
    "# Data folder\n",
    "data_folder = \"/PHShome/cs1839/capstone_data/\"\n",
    "# results table path\n",
    "results_df_path = data_folder + \"results.csv\"\n",
    "\n",
    "result_df = pd.read_csv(results_df_path).round(3)\n",
    "\n",
    "result_df = result_df._append({'Prompt': 'Create a bulleted list of which medications are mentioned and whether they are active, discontinued, or neither.',\n",
    "                   'Dataset': 'MIT', \n",
    "                   'Model': 'GPT-3 + R(32 LOC)(0-Shot)',\n",
    "                   'extraction_precision': 0.87,\n",
    "                   'extraction_recall': 0.83,\n",
    "                   'extraction_f1': round(2 * 0.87 * 0.83 / (0.87 + 0.83),3),\n",
    "                   'conditional_accuracy': 0.85,\n",
    "                   'conditional_macro_f1': 0.69,\n",
    "                   'conditional_macro_precision': '--',\n",
    "                   'conditional_macro_recall': '--'}, ignore_index=True)\n",
    "\n",
    "\n",
    "result_df = result_df._append({'Prompt': 'Create a bulleted list of which medications are mentioned and whether they are active, discontinued, or neither.',\n",
    "                   'Dataset': 'MIT', \n",
    "                   'Model': 'GPT-3 + R(8 LOC)(1-Shot)',\n",
    "                   'extraction_precision': 0.90,\n",
    "                   'extraction_recall': 0.92,\n",
    "                    'extraction_f1': round(2 * 0.90 * 0.92 / (0.90 + 0.92),3),\n",
    "                   'conditional_accuracy': 0.89,\n",
    "                   'conditional_macro_f1': 0.62,\n",
    "                   'conditional_macro_precision': '--',\n",
    "                   'conditional_macro_recall': '--'}, ignore_index=True)\n",
    "\n",
    "result_df[result_df.Dataset != 'Internal Data'].\\\n",
    "sort_values(\n",
    "    by=['Prompt', 'Dataset', 'extraction_f1', 'conditional_accuracy', 'conditional_macro_f1'],\n",
    "    ascending=[True, False, False, False, False] \n",
    ").set_index(['Prompt', 'Dataset', 'Model'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>extraction_precision</th>\n",
       "      <th>extraction_recall</th>\n",
       "      <th>extraction_f1</th>\n",
       "      <th>conditional_accuracy</th>\n",
       "      <th>conditional_macro_f1</th>\n",
       "      <th>conditional_macro_precision</th>\n",
       "      <th>conditional_macro_recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prompt</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"14\" valign=\"top\">Input Medical Note:\\n{}\\n\\nCreate a bulleted list of which medications are mentioned and whether they are active, discontinued. This dataset will only be evaluated on the following medications: 'prochlorperazine', 'compazine', 'navane', 'fluphenazine', 'haldol', 'haloperidol', 'pimozide', 'STELAZINE', 'THORAZINE', 'prolixin', 'perphenazine', 'sertraline', 'memantine', 'chlorproMAZINE', 'loxapine'.\\n\\nExpected Output Format:\\n- Current Medications (Active): Medication_1, Medication_2\\n- Discontinued Medications: Medication_3, Medication_4\\nEND\\n\\nOutput:\\n</th>\n",
       "      <th rowspan=\"14\" valign=\"top\">Internal Data</th>\n",
       "      <th>Qwen2.5-14B-Instruct</th>\n",
       "      <td>0.209</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meditron-70b</th>\n",
       "      <td>0.320</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.451</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.635</td>\n",
       "      <td>0.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-Nemo-Instruct-2407</th>\n",
       "      <td>0.498</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.607</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.1-70B-Instruct</th>\n",
       "      <td>0.579</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.626</td>\n",
       "      <td>0.539</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.1-8B</th>\n",
       "      <td>0.183</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.426</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.2-3B-Instruct</th>\n",
       "      <td>0.186</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.439</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen2-7B-Instruct</th>\n",
       "      <td>0.227</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen2.5-32B-Instruct</th>\n",
       "      <td>0.344</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen2.5-72B-Instruct</th>\n",
       "      <td>0.771</td>\n",
       "      <td>0.546</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.3</th>\n",
       "      <td>0.195</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.1-8B-Instruct</th>\n",
       "      <td>0.302</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.491</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meditron-7b</th>\n",
       "      <td>0.083</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen2-72B-Instruct</th>\n",
       "      <td>0.229</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.318</td>\n",
       "      <td>0.958</td>\n",
       "      <td>0.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.2-1B-Instruct</th>\n",
       "      <td>0.095</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                             extraction_precision  \\\n",
       "Prompt                                             Dataset       Model                                              \n",
       "Input Medical Note:\\n{}\\n\\nCreate a bulleted li... Internal Data Qwen2.5-14B-Instruct                       0.209   \n",
       "                                                                 meditron-70b                               0.320   \n",
       "                                                                 Mistral-Nemo-Instruct-2407                 0.498   \n",
       "                                                                 Llama-3.1-70B-Instruct                     0.579   \n",
       "                                                                 Llama-3.1-8B                               0.183   \n",
       "                                                                 Llama-3.2-3B-Instruct                      0.186   \n",
       "                                                                 Qwen2-7B-Instruct                          0.227   \n",
       "                                                                 Qwen2.5-32B-Instruct                       0.344   \n",
       "                                                                 Qwen2.5-72B-Instruct                       0.771   \n",
       "                                                                 Mistral-7B-Instruct-v0.3                   0.195   \n",
       "                                                                 Llama-3.1-8B-Instruct                      0.302   \n",
       "                                                                 meditron-7b                                0.083   \n",
       "                                                                 Qwen2-72B-Instruct                         0.229   \n",
       "                                                                 Llama-3.2-1B-Instruct                      0.095   \n",
       "\n",
       "                                                                                             extraction_recall  \\\n",
       "Prompt                                             Dataset       Model                                           \n",
       "Input Medical Note:\\n{}\\n\\nCreate a bulleted li... Internal Data Qwen2.5-14B-Instruct                    0.840   \n",
       "                                                                 meditron-70b                            0.761   \n",
       "                                                                 Mistral-Nemo-Instruct-2407              0.708   \n",
       "                                                                 Llama-3.1-70B-Instruct                  0.680   \n",
       "                                                                 Llama-3.1-8B                            0.667   \n",
       "                                                                 Llama-3.2-3B-Instruct                   0.638   \n",
       "                                                                 Qwen2-7B-Instruct                       0.588   \n",
       "                                                                 Qwen2.5-32B-Instruct                    0.565   \n",
       "                                                                 Qwen2.5-72B-Instruct                    0.546   \n",
       "                                                                 Mistral-7B-Instruct-v0.3                0.461   \n",
       "                                                                 Llama-3.1-8B-Instruct                   0.435   \n",
       "                                                                 meditron-7b                             0.203   \n",
       "                                                                 Qwen2-72B-Instruct                      0.202   \n",
       "                                                                 Llama-3.2-1B-Instruct                   0.077   \n",
       "\n",
       "                                                                                             extraction_f1  \\\n",
       "Prompt                                             Dataset       Model                                       \n",
       "Input Medical Note:\\n{}\\n\\nCreate a bulleted li... Internal Data Qwen2.5-14B-Instruct                0.335   \n",
       "                                                                 meditron-70b                        0.451   \n",
       "                                                                 Mistral-Nemo-Instruct-2407          0.585   \n",
       "                                                                 Llama-3.1-70B-Instruct              0.626   \n",
       "                                                                 Llama-3.1-8B                        0.287   \n",
       "                                                                 Llama-3.2-3B-Instruct               0.289   \n",
       "                                                                 Qwen2-7B-Instruct                   0.327   \n",
       "                                                                 Qwen2.5-32B-Instruct                0.427   \n",
       "                                                                 Qwen2.5-72B-Instruct                0.639   \n",
       "                                                                 Mistral-7B-Instruct-v0.3            0.274   \n",
       "                                                                 Llama-3.1-8B-Instruct               0.356   \n",
       "                                                                 meditron-7b                         0.118   \n",
       "                                                                 Qwen2-72B-Instruct                  0.214   \n",
       "                                                                 Llama-3.2-1B-Instruct               0.085   \n",
       "\n",
       "                                                                                             conditional_accuracy  \\\n",
       "Prompt                                             Dataset       Model                                              \n",
       "Input Medical Note:\\n{}\\n\\nCreate a bulleted li... Internal Data Qwen2.5-14B-Instruct                       0.169   \n",
       "                                                                 meditron-70b                               0.223   \n",
       "                                                                 Mistral-Nemo-Instruct-2407                 0.416   \n",
       "                                                                 Llama-3.1-70B-Instruct                     0.539   \n",
       "                                                                 Llama-3.1-8B                               0.123   \n",
       "                                                                 Llama-3.2-3B-Instruct                      0.123   \n",
       "                                                                 Qwen2-7B-Instruct                          0.171   \n",
       "                                                                 Qwen2.5-32B-Instruct                       0.276   \n",
       "                                                                 Qwen2.5-72B-Instruct                       0.707   \n",
       "                                                                 Mistral-7B-Instruct-v0.3                   0.153   \n",
       "                                                                 Llama-3.1-8B-Instruct                      0.238   \n",
       "                                                                 meditron-7b                                0.065   \n",
       "                                                                 Qwen2-72B-Instruct                         0.218   \n",
       "                                                                 Llama-3.2-1B-Instruct                      0.058   \n",
       "\n",
       "                                                                                             conditional_macro_f1  \\\n",
       "Prompt                                             Dataset       Model                                              \n",
       "Input Medical Note:\\n{}\\n\\nCreate a bulleted li... Internal Data Qwen2.5-14B-Instruct                       0.686   \n",
       "                                                                 meditron-70b                               0.389   \n",
       "                                                                 Mistral-Nemo-Instruct-2407                 0.607   \n",
       "                                                                 Llama-3.1-70B-Instruct                     0.760   \n",
       "                                                                 Llama-3.1-8B                               0.426   \n",
       "                                                                 Llama-3.2-3B-Instruct                      0.439   \n",
       "                                                                 Qwen2-7B-Instruct                          0.532   \n",
       "                                                                 Qwen2.5-32B-Instruct                       0.508   \n",
       "                                                                 Qwen2.5-72B-Instruct                       0.584   \n",
       "                                                                 Mistral-7B-Instruct-v0.3                   0.479   \n",
       "                                                                 Llama-3.1-8B-Instruct                      0.491   \n",
       "                                                                 meditron-7b                                0.183   \n",
       "                                                                 Qwen2-72B-Instruct                         0.318   \n",
       "                                                                 Llama-3.2-1B-Instruct                      0.102   \n",
       "\n",
       "                                                                                            conditional_macro_precision  \\\n",
       "Prompt                                             Dataset       Model                                                    \n",
       "Input Medical Note:\\n{}\\n\\nCreate a bulleted li... Internal Data Qwen2.5-14B-Instruct                             0.776   \n",
       "                                                                 meditron-70b                                     0.635   \n",
       "                                                                 Mistral-Nemo-Instruct-2407                       0.847   \n",
       "                                                                 Llama-3.1-70B-Instruct                           0.898   \n",
       "                                                                 Llama-3.1-8B                                     0.596   \n",
       "                                                                 Llama-3.2-3B-Instruct                            0.532   \n",
       "                                                                 Qwen2-7B-Instruct                                  0.7   \n",
       "                                                                 Qwen2.5-32B-Instruct                               0.7   \n",
       "                                                                 Qwen2.5-72B-Instruct                             0.914   \n",
       "                                                                 Mistral-7B-Instruct-v0.3                          0.75   \n",
       "                                                                 Llama-3.1-8B-Instruct                            0.772   \n",
       "                                                                 meditron-7b                                      0.405   \n",
       "                                                                 Qwen2-72B-Instruct                               0.958   \n",
       "                                                                 Llama-3.2-1B-Instruct                            0.461   \n",
       "\n",
       "                                                                                            conditional_macro_recall  \n",
       "Prompt                                             Dataset       Model                                                \n",
       "Input Medical Note:\\n{}\\n\\nCreate a bulleted li... Internal Data Qwen2.5-14B-Instruct                          0.623  \n",
       "                                                                 meditron-70b                                  0.397  \n",
       "                                                                 Mistral-Nemo-Instruct-2407                    0.515  \n",
       "                                                                 Llama-3.1-70B-Instruct                        0.665  \n",
       "                                                                 Llama-3.1-8B                                  0.368  \n",
       "                                                                 Llama-3.2-3B-Instruct                         0.374  \n",
       "                                                                 Qwen2-7B-Instruct                             0.429  \n",
       "                                                                 Qwen2.5-32B-Instruct                          0.399  \n",
       "                                                                 Qwen2.5-72B-Instruct                          0.446  \n",
       "                                                                 Mistral-7B-Instruct-v0.3                      0.354  \n",
       "                                                                 Llama-3.1-8B-Instruct                         0.406  \n",
       "                                                                 meditron-7b                                   0.118  \n",
       "                                                                 Qwen2-72B-Instruct                            0.191  \n",
       "                                                                 Llama-3.2-1B-Instruct                         0.058  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df[result_df.Dataset == 'Internal Data'].\\\n",
    "sort_values(\n",
    "    by=['Prompt', 'Dataset', 'extraction_recall', 'conditional_accuracy', 'conditional_macro_f1'],\n",
    "    ascending=[True, False, False, False, False] \n",
    ").set_index(['Prompt', 'Dataset', 'Model'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
