{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: adjust this according to your input data.\n",
    "mode_decoding = \"not greedy\"\n",
    "max_tokens = 700\n",
    "seed = 42\n",
    "frequency_penalty = 0\n",
    "presence_penalty = 0\n",
    "\n",
    "if mode_decoding == \"greedy\":\n",
    "    temperature = 0\n",
    "    top_p = 0\n",
    "else:\n",
    "    temperature = 0.1\n",
    "    top_p = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch query\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Client initialization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use the code below to generate 2 batch JSONL files for your task and send the generated JSONL file to me\n",
    "# model_name_batch = \"gpt-35-turbo-batch\"\n",
    "model_name_batch = \"gpt-4o-batch\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 14 prompt templates for prefix \"Other\"\n",
      "Loaded 14 prompt templates for prefix \"Other\"\n",
      "Loaded 14 prompt templates for prefix \"Internal Data\"\n",
      "MIT: 2800\n",
      "MIMIV: 8372\n",
      "Internal Data: 6748\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "import json\n",
    "\n",
    "def load_prompt_templates(prompt_file_path, template_key_prefix):\n",
    "    \"\"\"Load prompt templates from a JSON file, filtering by prefix.\"\"\"\n",
    "    with open(prompt_file_path, 'r') as file:\n",
    "        prompt_templates_json = json.load(file)\n",
    "    \n",
    "    # Filter keys that start with the specified prefix\n",
    "    prompt_templates_with_keys = [\n",
    "        (key, prompt_templates_json[key])\n",
    "        for key in prompt_templates_json\n",
    "        if key.startswith(template_key_prefix)\n",
    "    ]\n",
    "    \n",
    "    if not prompt_templates_with_keys:\n",
    "        raise KeyError(f\"No templates found for the key prefix: {template_key_prefix}\")\n",
    "    \n",
    "    print(f'Loaded {len(prompt_templates_with_keys)} prompt templates for prefix \"{template_key_prefix}\"')\n",
    "    return prompt_templates_with_keys\n",
    "\n",
    "def get_input_prompt(data_path, prompt_path):\n",
    "    if 'PPV' in data_path:\n",
    "        dataset_name = \"Internal Data\"\n",
    "    else:\n",
    "        dataset_name = \"External Data\"\n",
    "\n",
    "    input_df = pd.read_csv(data_path)\n",
    "    input_df.loc[:, 'active_medications'] = input_df['active_medications'].apply(lambda x: literal_eval(x)).apply(lambda x: [med.lower() for med in x])\n",
    "    input_df.loc[:, 'discontinued_medications'] = input_df['discontinued_medications'].apply(lambda x: literal_eval(x)).apply(lambda x: [med.lower() for med in x])\n",
    "    if dataset_name != \"Internal Data\":\n",
    "        input_df.loc[:, 'neither_medications'] = input_df['neither_medications'].apply(lambda x: literal_eval(x)).apply(lambda x: [med.lower() for med in x])\n",
    "\n",
    "    col_list = ['active_medications', 'discontinued_medications', 'neither_medications'] if dataset_name != \"Internal Data\" else ['active_medications', 'discontinued_medications']\n",
    "    true_set = input_df[col_list].apply(lambda x: set([med for meds in x for med in meds]), axis=1)\n",
    "\n",
    "    snippets = input_df['snippet'].values.tolist()\n",
    "\n",
    "    # load prompt.json\n",
    "    prompt_prefix = 'Other' if dataset_name != \"Internal Data\" else 'Internal Data'\n",
    "    prompts = load_prompt_templates(prompt_path, prompt_prefix)\n",
    "    \n",
    "    input_list = []\n",
    "    prompt_key = []\n",
    "    for prompt_key, prompt_template in prompts:\n",
    "        input_list.extend([prompt_template.format(snippet) for snippet in snippets])\n",
    "        \n",
    "        ### add prompt for classification with true set\n",
    "        p_list = prompt_template.split(\"\\nOutput:\") \n",
    "        # insert to the second last element\n",
    "        insert = \"Hint: Here is a complete list of medications included in this note: {}. Assign a status for each of them.\\n\"\n",
    "        # rejoin the prompt template to have the option to insert the hint\n",
    "        prompt_template = '\\nOutput:'.join(p_list[:-1]) + insert + \"\\nOutput:\" + p_list[-1]\n",
    "        input_list.extend([prompt_template.format(snippet, ground_truth) for snippet, ground_truth in zip(snippets, true_set)])\n",
    "\n",
    "    return input_list\n",
    "\n",
    "data_folder = '/PHShome/cs1839/capstone_data/'\n",
    "input_for_MIT = get_input_prompt(data_folder + 'medication_status_test.csv', 'prompts.json')\n",
    "input_for_MIMIV = get_input_prompt(data_folder + 'mimic_iv_snippets_list_new.csv', 'prompts.json')\n",
    "input_for_internal_data = get_input_prompt(data_folder + 'PPV_snippet_medications.csv', 'prompts.json')\n",
    "\n",
    "# print the length of the prompts for each dataset\n",
    "print('MIT:', len(input_for_MIT))\n",
    "print('MIMIV:', len(input_for_MIMIV))\n",
    "print('Internal Data:', len(input_for_internal_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of prompts: 89600\n"
     ]
    }
   ],
   "source": [
    "# TODO: Put your input here\n",
    "# there are 5 simulations for each prompt\n",
    "list_data = input_for_MIT*5 + input_for_MIMIV*5 + input_for_internal_data*5   \n",
    "\n",
    "print(\"Total number of prompts:\", len(list_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = '''You are a clinical assistant AI specialized in processing medical notes. Your primary tasks are:\n",
    "1. Accurately extracting all mentioned medications as it is in the input notes.\n",
    "2. Determining the status of each medication (active, discontinued, or neither) based on the context provided in the medical notes.\n",
    "\n",
    "Your goal is to provide clear, accurate, and concise results, avoiding irrelevant information or hallucinations. Follow the specific task instructions provided in the user prompts to guide your outputs.\n",
    "''' # TODO: Put your system message here (if applicable)\n",
    "\n",
    "list_dict_data_batch = []\n",
    "for idx, data in enumerate(list_data):\n",
    "    dict_data_batch = {\n",
    "        \"custom_id\": f\"{idx}\",\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/chat/completions\",\n",
    "        \"body\": {\n",
    "            \"model\": model_name_batch,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": system_message}, # TODO: If no system message, then comment this line out\n",
    "                {\"role\": \"user\", \"content\": data},\n",
    "            ],\n",
    "            \"temperature\": temperature,\n",
    "            \"top_p\": top_p,\n",
    "            \"frequency_penalty\": frequency_penalty,\n",
    "            \"presence_penalty\": presence_penalty,\n",
    "            \"max_tokens\": max_tokens,\n",
    "        },\n",
    "    }\n",
    "    list_dict_data_batch.append(dict_data_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 89600 data into data_batch_gpt-4o-batch.jsonl\n"
     ]
    }
   ],
   "source": [
    "# save into jsonl\n",
    "path_file_data_batch = f\"data_batch_{model_name_batch}.jsonl\"\n",
    "with open(path_file_data_batch, \"w\", encoding=\"utf-8\") as f:\n",
    "    for dict_data_batch in list_dict_data_batch:\n",
    "        f.write(json.dumps(dict_data_batch, ensure_ascii=False) + \"\\n\")\n",
    "print(f\"Saved {len(list_dict_data_batch)} data into {path_file_data_batch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After you send the 2 JSONL files to me, I will run the batch jobs for you using the 2 models and give you the \"result_batch_{model_name_batch}.jsonl\" files. Please use the code below to fetch the model output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "path_file_result_batch = \"/PHShome/cs1839/capstone_data/jsonl/data_batch_gpt-4o-batch_result.jsonl\"\n",
    "path_input_filtered = \"/PHShome/cs1839/capstone_data/jsonl/data_batch_gpt-4o-batch_input_filter_result.jsonl\"\n",
    "path_output_filtered = \"/PHShome/cs1839/capstone_data/jsonl/data_batch_gpt-4o-batch_output_filter_result.jsonl\"\n",
    "\n",
    "info_dict = {}\n",
    "result_list = []\n",
    "token_usage_dict_list = []\n",
    "with open(path_file_result_batch, \"r\", encoding=\"utf-8\") as f:\n",
    "    list_dict_result = sorted([json.loads(line) for line in f.readlines()], key=lambda x: x[\"custom_id\"])\n",
    "    for model_response_dict in list_dict_result:\n",
    "        id = int(model_response_dict[\"custom_id\"])\n",
    "        try:\n",
    "            model_response_str = model_response_dict['response']['body']['choices'][0]['message']['content']\n",
    "        except: # The result is filtered by the safety filter, return empty string\n",
    "            model_response_str = \"\"\n",
    "        token_usage = model_response_dict['response']['body']['usage'] # Token (input, output, and total) usage for each sample\n",
    "        info_dict[id] = (model_response_str, token_usage)\n",
    "\n",
    "not_returned = []\n",
    "filtered = []\n",
    "for i in range(0, 89600):\n",
    "    if i in info_dict:\n",
    "        model_response_str, token_usage = info_dict[i]\n",
    "        if model_response_str == \"\":\n",
    "            filtered.append(i)\n",
    "        result_list.append(model_response_str)\n",
    "        token_usage_dict_list.append(token_usage)\n",
    "    else:\n",
    "        result_list.append(\"\")\n",
    "        token_usage_dict_list.append({})\n",
    "        not_returned.append(i)\n",
    "        \n",
    "# update the output content filtered by the safety filter\n",
    "with open(path_output_filtered, \"r\", encoding=\"utf-8\") as f:\n",
    "    output_filtered_list_dict_result = sorted([json.loads(line) for line in f.readlines()], key=lambda x: int(x[\"custom_id\"]))\n",
    "    for model_response_dict in output_filtered_list_dict_result:\n",
    "        id = int(model_response_dict[\"custom_id\"])\n",
    "        try:\n",
    "            model_response_str = model_response_dict['response']['body']['choices'][0]['message']['content']\n",
    "        except: # The result is filtered by the safety filter, return empty string\n",
    "            print('id:', id)\n",
    "            model_response_str = \"\"\n",
    "        token_usage = model_response_dict['response']['body']['usage'] # Token (input, output, and total) usage for each sample\n",
    "        info_dict[id] = (model_response_str, token_usage)\n",
    "\n",
    "        # update the result_list and token_usage_dict_list\n",
    "        result_list[id] = model_response_str\n",
    "        info_dict[id] = (model_response_str, token_usage)\n",
    "\n",
    "# update the input content filtered by the safety filter\n",
    "with open(path_input_filtered, \"r\", encoding=\"utf-8\") as f:\n",
    "    input_filtered_list_dict_result = sorted([json.loads(line) for line in f.readlines()], key=lambda x: int(x[\"custom_id\"]))\n",
    "    for model_response_dict in input_filtered_list_dict_result:\n",
    "        id = int(model_response_dict[\"custom_id\"])\n",
    "        try:\n",
    "            model_response_str = model_response_dict['response']['body']['choices'][0]['message']['content']\n",
    "        except: # The result is filtered by the safety filter, return empty string\n",
    "            print('id:', id)\n",
    "            model_response_str = \"\"\n",
    "        token_usage = model_response_dict['response']['body']['usage'] # Token (input, output, and total) usage for each sample\n",
    "        info_dict[id] = (model_response_str, token_usage)\n",
    "\n",
    "        # update the result_list and token_usage_dict_list\n",
    "        result_list[id] = model_response_str\n",
    "        info_dict[id] = (model_response_str, token_usage)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty: []\n"
     ]
    }
   ],
   "source": [
    "# check any item in the result_list is empty\n",
    "empty = [i for i, x in enumerate(result_list) if x == \"\"]\n",
    "print('Empty:', empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89600\n",
      "89600\n",
      "Number of samples that are not returned: 10\n",
      "Custom IDs of the not returned samples that are not returned: [2088, 2188, 4888, 4988, 7688, 7788, 10488, 10588, 13288, 13388]\n",
      "Number of samples that are filtered: 4130\n",
      "Custom IDs of the not returned samples that are filtered: [200, 225, 240, 300, 325, 340, 400, 440, 500, 525, 540, 600, 625, 640, 671, 700, 725, 740, 800, 825, 840, 900, 940, 1000, 1020, 1025, 1040, 1100, 1125, 1140, 1595, 1695, 1795, 1808, 1840, 1908, 1940, 1995, 2005, 2008, 2040, 2140, 2195, 2208, 2240, 2274, 2308, 2340, 2374, 2395, 2400, 2425, 2440, 2500, 2525, 2540, 2795, 3000, 3025, 3040, 3125, 3140, 3200, 3325, 3340, 3400, 3425, 3440, 3471, 3500, 3525, 3540, 3600, 3640, 3700, 3725, 3740, 3800, 3820, 3840, 3900, 3920, 3925, 3940, 4408, 4495, 4540, 4595, 4608, 4640, 4708, 4740, 4795, 4800, 4808, 4840, 4854, 4940, 4995, 5008, 5040, 5108, 5140, 5195, 5200, 5225, 5240, 5300, 5325, 5340, 5495, 5508, 5540, 5595, 5800, 5825, 5840, 5871, 5900, 5925, 5940, 6000, 6025, 6125, 6140, 6200, 6225, 6240, 6271, 6300, 6325, 6340, 6400, 6440, 6471, 6500, 6525, 6600, 6620, 6625, 6640, 6700, 6720, 6723, 6725, 6740, 7095, 7295, 7340, 7395, 7408, 7440, 7508, 7540, 7595, 7640, 7654, 7740, 7795, 7808, 7840, 7874, 7908, 7940, 7995, 8000, 8025, 8040, 8100, 8125, 8140, 8395, 8600, 8625, 8640, 8671, 8700, 8725, 8740, 8800, 8825, 8900, 8940, 9000, 9025, 9040, 9071, 9100, 9125, 9140, 9200, 9225, 9240, 9300, 9340, 9400, 9420, 9425, 9440, 9500, 9520, 9525, 9540, 9895, 10195, 10208, 10308, 10395, 10400, 10405, 10408, 10440, 10454, 10540, 10595, 10608, 10640, 10674, 10708, 10740, 10795, 10825, 10840, 10900, 10925, 10940, 11095, 11400, 11425, 11440, 11471, 11525, 11540, 11600, 11625, 11640, 11700, 11725, 11740, 11800, 11825, 11840, 11871, 11900, 11925, 11940, 12000, 12025, 12040, 12060, 12071, 12100, 12125, 12140, 12200, 12220, 12240, 12300, 12325, 12340, 12895, 12908, 12995, 13005, 13008, 13040, 13074, 13108, 13140, 13195, 13200, 13205, 13240, 13340, 13395, 13408, 13440, 13474, 13508, 13540, 13595, 13600, 13625, 13640, 13671, 13700, 13725, 13740, 13874, 13895, 13995, 14218, 14517, 14632, 14689, 14690, 14708, 14750, 14777, 14800, 14816, 14838, 14871, 14875, 14880, 14966, 14989, 15000, 15028, 15049, 15076, 15115, 15125, 15137, 15144, 15173, 15174, 15287, 15288, 15299, 15300, 15306, 15349, 15398, 15414, 15420, 15422, 15452, 15469, 15473, 15478, 15586, 15587, 15598, 15647, 15674, 15697, 15713, 15723, 15772, 15777, 15796, 15797, 15885, 15886, 15897, 15898, 15903, 15914, 15946, 15956, 15973, 15996, 16010, 16012, 16020, 16022, 16034, 16067, 16068, 16071, 16095, 16096, 16155, 16162, 16184, 16185, 16196, 16201, 16202, 16203, 16245, 16272, 16311, 16317, 16319, 16321, 16340, 16352, 16361, 16366, 16369, 16370, 16391, 16426, 16448, 16483, 16484, 16495, 16496, 16501, 16502, 16512, 16545, 16564, 16571, 16594, 16610, 16617, 16620, 16632, 16648, 16665, 16669, 16674, 16693, 16731, 16760, 16782, 16783, 16794, 16795, 16799, 16800, 16801, 16843, 16865, 16870, 16893, 16909, 16917, 16919, 16938, 16964, 16968, 16973, 16992, 17046, 17081, 17082, 17093, 17094, 17096, 17099, 17100, 17121, 17142, 17162, 17169, 17192, 17206, 17208, 17215, 17216, 17218, 17230, 17263, 17267, 17291, 17292, 17329, 17345, 17358, 17380, 17381, 17392, 17393, 17397, 17398, 17399, 17420, 17441, 17463, 17468, 17491, 17507, 17515, 17517, 17529, 17536, 17562, 17566, 18398, 18482, 18821, 18845, 19023, 19078, 19232, 19277, 19301, 19322, 19365, 19419, 19443, 19600, 19718, 19875, 19891, 19920, 19957, 19963, 20017, 20040, 20041, 20133, 20157, 20169, 20192, 20219, 20262, 20316, 20340, 20456, 20473, 20491, 20497, 20505, 20518, 20688, 20772, 20817, 20860, 20874, 20914, 21071, 21095, 21116, 21159, 21165, 21173, 21178, 21210, 21267, 21268, 21279, 21285, 21286, 21296, 21328, 21329, 21355, 21378, 21394, 21400, 21404, 21416, 21449, 21453, 21458, 21477, 21478, 21544, 21566, 21567, 21578, 21579, 21584, 21627, 21647, 21654, 21693, 21699, 21701, 21703, 21715, 21722, 21748, 21751, 21752, 21992, 22283, 22291, 22590, 22889, 23004, 23061, 23062, 23073, 23074, 23080, 23172, 23188, 23210, 23243, 23247, 23252, 23271, 23360, 23361, 23372, 23421, 23448, 23487, 23497, 23516, 23542, 23546, 23660, 23671, 23677, 23678, 23747, 23770, 23786, 23792, 23841, 23845, 23850, 23958, 23959, 23970, 24019, 24046, 24069, 24085, 24095, 24135, 24144, 24149, 24168, 24169, 24228, 24257, 24258, 24269, 24270, 24275, 24286, 24318, 24345, 24368, 24384, 24392, 24394, 24406, 24439, 24443, 24448, 24467, 24468, 24505, 24527, 24534, 24556, 24557, 24568, 24573, 24574, 24617, 24644, 24683, 24691, 24693, 24712, 24733, 24738, 24741, 24742, 24747, 24763, 24766, 24798, 24819, 24855, 24856, 24867, 24868, 24873, 24874, 24936, 24943, 24966, 24982, 24992, 25004, 25037, 25041, 25046, 25065, 25066, 25103, 25132, 25154, 25155, 25166, 25173, 25215, 25242, 25281, 25289, 25291, 25310, 25336, 25339, 25340, 25345, 25364, 25365, 25418, 25453, 25454, 25465, 25466, 25468, 25471, 25472, 25482, 25493, 25513, 25514, 25534, 25541, 25564, 25578, 25580, 25586, 25587, 25588, 25590, 25602, 25635, 25639, 25663, 25664, 25717, 25730, 25752, 25753, 25764, 25765, 25767, 25769, 25770, 25771, 25792, 25813, 25835, 25840, 25863, 25879, 25887, 25889, 25901, 25908, 25934, 25938, 26359, 26524, 26770, 26846, 26854, 27193, 27217, 27350, 27368, 27555, 27665, 27673, 27694, 27737, 27791, 27948, 27956, 27972, 27993, 28036, 28050, 28090, 28247, 28263, 28265, 28329, 28335, 28389, 28505, 28529, 28541, 28564, 28591, 28627, 28688, 28712, 28828, 28845, 28869, 28890, 28933, 28987, 29144, 29160, 29189, 29232, 29246, 29286, 29443, 29467, 29488, 29537, 29550, 29582, 29640, 29651, 29652, 29657, 29658, 29668, 29699, 29700, 29701, 29727, 29750, 29766, 29772, 29776, 29788, 29804, 29821, 29825, 29830, 29849, 29850, 29887, 29916, 29938, 29939, 29950, 29951, 29956, 29999, 30019, 30026, 30065, 30071, 30075, 30087, 30094, 30120, 30123, 30124, 30145, 30183, 30207, 30356, 30364, 30506, 30655, 30663, 31261, 31325, 31376, 31433, 31434, 31445, 31494, 31514, 31544, 31560, 31570, 31582, 31615, 31619, 31624, 31643, 31732, 31733, 31744, 31793, 31820, 31859, 31867, 31869, 31888, 31917, 31918, 32032, 32043, 32044, 32049, 32060, 32093, 32142, 32158, 32164, 32166, 32180, 32213, 32217, 32330, 32331, 32342, 32348, 32391, 32418, 32441, 32457, 32463, 32465, 32467, 32486, 32515, 32516, 32521, 32537, 32540, 32541, 32572, 32629, 32630, 32641, 32642, 32647, 32658, 32690, 32691, 32717, 32740, 32756, 32764, 32766, 32778, 32811, 32815, 32820, 32839, 32877, 32899, 32906, 32928, 32929, 32940, 32946, 32989, 33016, 33055, 33063, 33065, 33084, 33093, 33096, 33110, 33113, 33114, 33119, 33135, 33138, 33170, 33227, 33228, 33239, 33240, 33245, 33246, 33289, 33308, 33315, 33338, 33354, 33364, 33376, 33392, 33409, 33413, 33418, 33437, 33438, 33475, 33526, 33527, 33538, 33544, 33545, 33587, 33614, 33637, 33653, 33661, 33663, 33682, 33708, 33711, 33736, 33737, 33790, 33825, 33826, 33837, 33838, 33840, 33843, 33844, 33865, 33884, 33885, 33886, 33906, 33913, 33936, 33950, 33952, 33959, 33960, 33962, 33974, 34007, 34011, 34035, 34036, 34073, 34089, 34095, 34102, 34124, 34125, 34136, 34137, 34141, 34142, 34143, 34164, 34185, 34207, 34212, 34224, 34235, 34251, 34259, 34261, 34273, 34280, 34306, 34310, 35565, 35722, 35767, 36021, 36045, 36066, 36080, 36103, 36109, 36163, 36328, 36338, 36365, 36408, 36422, 36462, 36486, 36619, 36643, 36664, 36707, 36761, 36858, 36877, 36901, 36913, 36918, 36936, 36942, 37060, 37084, 37123, 37200, 37217, 37241, 37262, 37383, 37432, 37516, 37532, 37561, 37575, 37604, 37618, 37815, 37823, 37860, 37897, 37903, 37909, 37954, 38011, 38012, 38024, 38029, 38040, 38071, 38072, 38073, 38092, 38099, 38122, 38138, 38144, 38146, 38160, 38176, 38193, 38197, 38202, 38222, 38288, 38310, 38311, 38322, 38323, 38371, 38391, 38398, 38437, 38443, 38447, 38459, 38466, 38492, 38495, 38496, 38579, 38671, 38736, 38878, 39027, 39035, 39633, 39748, 39805, 39806, 39823, 39824, 39886, 39916, 39932, 39942, 39954, 39987, 39991, 39996, 40082, 40104, 40105, 40116, 40144, 40165, 40192, 40231, 40239, 40286, 40290, 40404, 40415, 40416, 40421, 40422, 40464, 40465, 40514, 40530, 40536, 40585, 40589, 40594, 40702, 40703, 40714, 40715, 40763, 40790, 40813, 40829, 40839, 40851, 40879, 40887, 40888, 40893, 40912, 40913, 40944, 41001, 41002, 41013, 41014, 41019, 41030, 41062, 41089, 41112, 41128, 41136, 41138, 41150, 41183, 41187, 41211, 41212, 41249, 41271, 41278, 41300, 41301, 41312, 41317, 41318, 41361, 41388, 41427, 41433, 41435, 41437, 41456, 41471, 41477, 41485, 41486, 41507, 41510, 41542, 41563, 41564, 41599, 41600, 41611, 41612, 41617, 41618, 41687, 41710, 41726, 41736, 41748, 41764, 41781, 41785, 41790, 41809, 41810, 41847, 41876, 41898, 41899, 41915, 41916, 41917, 41959, 41986, 42009, 42025, 42033, 42035, 42054, 42080, 42083, 42084, 42089, 42105, 42108, 42162, 42197, 42198, 42209, 42210, 42212, 42215, 42216, 42237, 42256, 42257, 42258, 42278, 42285, 42308, 42322, 42324, 42331, 42332, 42334, 42346, 42379, 42383, 42407, 42408, 42461, 42474, 42496, 42497, 42508, 42509, 42511, 42513, 42514, 42515, 42536, 42557, 42579, 42584, 42607, 42623, 42631, 42633, 42645, 42652, 42678, 42682, 42741, 43937, 44094, 44110, 44112, 44139, 44196, 44393, 44409, 44417, 44438, 44464, 44475, 44481, 44535, 44700, 44710, 44737, 44780, 44991, 45036, 45073, 45079, 45133, 45249, 45273, 45285, 45290, 45308, 45314, 45371, 45432, 45572, 45589, 45613, 45731, 45888, 45904, 45933, 45947, 45976, 45988, 45990, 46187, 46195, 46211, 46232, 46246, 46275, 46281, 46287, 46294, 46326, 46383, 46384, 46401, 46402, 46412, 46443, 46444, 46445, 46464, 46471, 46494, 46508, 46510, 46516, 46520, 46532, 46548, 46565, 46569, 46574, 46594, 46682, 46683, 46694, 46699, 46700, 46743, 46763, 46770, 46793, 46809, 46815, 46819, 46831, 46838, 46864, 46867, 46868, 47100, 47108, 47250, 47399, 47407, 47464, 48005, 48069, 48177, 48178, 48190, 48195, 48196, 48238, 48258, 48265, 48288, 48304, 48314, 48326, 48333, 48359, 48363, 48368, 48388, 48454, 48476, 48477, 48488, 48493, 48494, 48495, 48516, 48537, 48564, 48603, 48662, 48776, 48788, 48793, 48794, 48804, 48836, 48837, 48863, 48886, 48902, 48908, 48924, 48940, 48957, 48961, 48966, 48985, 49074, 49075, 49086, 49135, 49162, 49185, 49201, 49209, 49211, 49260, 49265, 49284, 49285, 49344, 49373, 49374, 49385, 49386, 49391, 49402, 49413, 49434, 49461, 49484, 49500, 49508, 49510, 49522, 49555, 49556, 49559, 49564, 49583, 49584, 49643, 49650, 49672, 49673, 49684, 49689, 49690, 49733, 49760, 49799, 49807, 49809, 49828, 49840, 49854, 49857, 49858, 49863, 49879, 49882, 49914, 49971, 49972, 49983, 49984, 49989, 49990, 50000, 50052, 50059, 50082, 50098, 50105, 50108, 50120, 50153, 50157, 50162, 50181, 50182, 50219, 50234, 50248, 50270, 50271, 50282, 50287, 50288, 50289, 50331, 50353, 50358, 50381, 50397, 50405, 50407, 50426, 50452, 50455, 50456, 50461, 50480, 50534, 50569, 50570, 50581, 50582, 50584, 50587, 50588, 50609, 50628, 50629, 50630, 50650, 50657, 50680, 50694, 50696, 50702, 50703, 50704, 50706, 50718, 50751, 50755, 50779, 50780, 50817, 50833, 50846, 50868, 50869, 50880, 50881, 50883, 50885, 50886, 50887, 50908, 50929, 50951, 50956, 50979, 50995, 51001, 51003, 51005, 51024, 51050, 51054, 51886, 51950, 51956, 51970, 52267, 52269, 52309, 52351, 52454, 52466, 52484, 52511, 52568, 52765, 52789, 52810, 52853, 52907, 53082, 53088, 53109, 53152, 53166, 53363, 53387, 53445, 53451, 53505, 53621, 53645, 53662, 53670, 53680, 53743, 53804, 53828, 53944, 53961, 53985, 54006, 54020, 54049, 54103, 54176, 54260, 54276, 54278, 54305, 54319, 54342, 54348, 54362, 54559, 54604, 54666, 54698, 54756, 54767, 54768, 54773, 54774, 54784, 54816, 54817, 54843, 54866, 54882, 54888, 54904, 54920, 54937, 54941, 54946, 54966, 55032, 55054, 55055, 55066, 55067, 55072, 55115, 55135, 55142, 55181, 55187, 55189, 55191, 55203, 55210, 55236, 55239, 55240, 55480, 55622, 55771, 55779, 55894, 55919, 55950, 55951, 55974, 55986, 55987, 56023, 56035, 56050, 56081, 56276, 56291, 56342, 56349, 56353, 56359, 56365, 56368, 56393, 56396, 56409, 56413, 56415, 56421, 56424, 56430, 56444, 56447, 56450, 56457, 56458, 56459, 56464, 56468, 56469, 56476, 56483, 56484, 56485, 56490, 56508, 56513, 56517, 56522, 56524, 56525, 56529, 56530, 56532, 56534, 56535, 56537, 56539, 56540, 56541, 56542, 56543, 56544, 56545, 56550, 56551, 56556, 56563, 56565, 56569, 56573, 56576, 56577, 56578, 56580, 56582, 56600, 56606, 56623, 56638, 56650, 56656, 56662, 56671, 56688, 56699, 56705, 56724, 56725, 56731, 56749, 56758, 56763, 56766, 56773, 56775, 56780, 56781, 56782, 56784, 56791, 56792, 56793, 56797, 56804, 56806, 56823, 56841, 56842, 56866, 56906, 56946, 56965, 56966, 56999, 57019, 57027, 57240, 57313, 57323, 57329, 57385, 57391, 57428, 57432, 57448, 57454, 57481, 57488, 57493, 57496, 57501, 57503, 57504, 57505, 57508, 57527, 57528, 57529, 57533, 57537, 57540, 57541, 57546, 57681, 57722, 57729, 57780, 57828, 57855, 57873, 57876, 57922, 57929, 57930, 57936, 57954, 57963, 57970, 57971, 57975, 57980, 57981, 57983, 57985, 57986, 57987, 57989, 57991, 57996, 57998, 58011, 58016, 58021, 58023, 58024, 58028, 58069, 58108, 58117, 58151, 58163, 58168, 58170, 58195, 58204, 58212, 58257, 58262, 58270, 58277, 58287, 58305, 58310, 58312, 58323, 58324, 58336, 58337, 58343, 58350, 58353, 58358, 58372, 58376, 58385, 58386, 58392, 58397, 58404, 58409, 58411, 58412, 58413, 58418, 58420, 58433, 58436, 58445, 58446, 58450, 58452, 58457, 58460, 58462, 58463, 58465, 58467, 58468, 58469, 58471, 58472, 58473, 58478, 58479, 58484, 58491, 58493, 58497, 58498, 58501, 58504, 58505, 58506, 58508, 58510, 58528, 58553, 58593, 58599, 58613, 58626, 58633, 58645, 58652, 58654, 58677, 58686, 58691, 58703, 58704, 58708, 58712, 58714, 58719, 58732, 58739, 58745, 58746, 58747, 58751, 59234, 59238, 59239, 59241, 59242, 59243, 59244, 59251, 59255, 59257, 59259, 59260, 59262, 59265, 59267, 59268, 59270, 59271, 59273, 59275, 59278, 59283, 59286, 59289, 59297, 59298, 59300, 59301, 59302, 59306, 59314, 59316, 59319, 59322, 59323, 59324, 59325, 59326, 59330, 59336, 59338, 59339, 59340, 59346, 59348, 59350, 59360, 59361, 59362, 59368, 59375, 59376, 59377, 59381, 59382, 59384, 59400, 59402, 59408, 59409, 59410, 59414, 59416, 59420, 59421, 59422, 59424, 59426, 59427, 59429, 59431, 59432, 59433, 59434, 59435, 59436, 59437, 59442, 59444, 59448, 59455, 59457, 59461, 59462, 59465, 59467, 59468, 59469, 59470, 59471, 59472, 59473, 59474, 59482, 59515, 59548, 59557, 59577, 59591, 59609, 59616, 59618, 59641, 59650, 59662, 59667, 59668, 59670, 59672, 59673, 59674, 59676, 59683, 59703, 59706, 59708, 59709, 59710, 59711, 59715, 59847, 60456, 60590, 60684, 60697, 60732, 60748, 60770, 60799, 60811, 60825, 60922, 60938, 61171, 61238, 61270, 61296, 61348, 61399, 61778, 62019, 62127, 62129, 62130, 62134, 62135, 62136, 62137, 62138, 62144, 62145, 62151, 62153, 62154, 62157, 62159, 62160, 62164, 62165, 62167, 62169, 62173, 62174, 62175, 62178, 62181, 62183, 62188, 62194, 62195, 62196, 62198, 62205, 62207, 62208, 62209, 62210, 62215, 62216, 62217, 62218, 62220, 62221, 62223, 62227, 62229, 62230, 62231, 62232, 62234, 62243, 62244, 62245, 62246, 62247, 62257, 62258, 62260, 62261, 62264, 62266, 62270, 62271, 62276, 62279, 62280, 62281, 62282, 62284, 62285, 62286, 62287, 62291, 62295, 62296, 62297, 62300, 62312, 62326, 62355, 62363, 62397, 62407, 62501, 62591, 62642, 62667, 62668, 62698, 62699, 62734, 62735, 62783, 62798, 62807, 63012, 63024, 63039, 63097, 63107, 63108, 63113, 63116, 63139, 63141, 63144, 63157, 63161, 63163, 63169, 63172, 63176, 63178, 63192, 63195, 63198, 63205, 63206, 63207, 63212, 63216, 63231, 63232, 63238, 63253, 63256, 63261, 63265, 63266, 63270, 63272, 63277, 63280, 63282, 63283, 63285, 63287, 63288, 63289, 63290, 63291, 63292, 63293, 63299, 63304, 63311, 63312, 63313, 63317, 63318, 63319, 63321, 63323, 63324, 63325, 63326, 63328, 63329, 63330, 63348, 63354, 63371, 63386, 63388, 63404, 63410, 63436, 63447, 63472, 63473, 63494, 63497, 63506, 63511, 63513, 63514, 63523, 63524, 63526, 63529, 63532, 63534, 63540, 63541, 63552, 63558, 63559, 63562, 63564, 63566, 63567, 63571, 63627, 63654, 63660, 63713, 63714, 63720, 63747, 63754, 63767, 63782, 63799, 63988, 64061, 64109, 64121, 64156, 64176, 64180, 64181, 64193, 64195, 64196, 64202, 64204, 64225, 64228, 64229, 64230, 64236, 64241, 64249, 64251, 64252, 64253, 64263, 64268, 64275, 64277, 64281, 64288, 64289, 64290, 64294, 64470, 64576, 64609, 64615, 64621, 64624, 64670, 64678, 64679, 64684, 64702, 64711, 64716, 64718, 64719, 64723, 64726, 64728, 64729, 64733, 64734, 64737, 64744, 64746, 64759, 64764, 64769, 64771, 64776, 64778, 64794, 64817, 64832, 64844, 64850, 64856, 64865, 64916, 64918, 64919, 64952, 64960, 64980, 64987, 65005, 65010, 65025, 65035, 65058, 65060, 65071, 65072, 65084, 65085, 65101, 65106, 65124, 65133, 65134, 65140, 65157, 65159, 65161, 65166, 65168, 65184, 65193, 65200, 65201, 65205, 65208, 65210, 65211, 65213, 65215, 65216, 65217, 65218, 65219, 65220, 65221, 65226, 65227, 65232, 65239, 65240, 65245, 65246, 65247, 65249, 65251, 65252, 65253, 65254, 65256, 65258, 65332, 65361, 65374, 65400, 65401, 65402, 65407, 65422, 65425, 65434, 65449, 65451, 65452, 65458, 65460, 65461, 65467, 65480, 65482, 65487, 65492, 65494, 65986, 65989, 65990, 65991, 65992, 65999, 66005, 66007, 66008, 66010, 66013, 66015, 66016, 66018, 66019, 66026, 66037, 66039, 66045, 66048, 66049, 66054, 66055, 66062, 66064, 66065, 66070, 66071, 66072, 66073, 66074, 66084, 66087, 66088, 66098, 66101, 66104, 66108, 66109, 66110, 66116, 66123, 66124, 66125, 66126, 66129, 66130, 66148, 66150, 66156, 66157, 66158, 66162, 66164, 66168, 66169, 66170, 66172, 66174, 66175, 66177, 66179, 66180, 66181, 66182, 66183, 66184, 66185, 66190, 66192, 66196, 66203, 66204, 66205, 66209, 66210, 66213, 66215, 66216, 66217, 66218, 66219, 66220, 66221, 66222, 66230, 66263, 66296, 66305, 66325, 66339, 66357, 66362, 66364, 66366, 66371, 66373, 66389, 66398, 66413, 66415, 66416, 66418, 66420, 66421, 66424, 66431, 66433, 66446, 66450, 66451, 66454, 66456, 66457, 66459, 66461, 66463, 66521, 67461, 67518, 67559, 67573, 67759, 67777, 67833, 67952, 67959, 68084, 68111, 68139, 68147, 68767, 68875, 68877, 68878, 68882, 68883, 68884, 68885, 68886, 68892, 68893, 68899, 68901, 68902, 68905, 68907, 68908, 68912, 68913, 68915, 68917, 68921, 68922, 68923, 68926, 68929, 68931, 68934, 68936, 68942, 68944, 68946, 68953, 68955, 68956, 68957, 68958, 68962, 68963, 68964, 68965, 68966, 68968, 68969, 68971, 68977, 68978, 68980, 68982, 68991, 68992, 68993, 68994, 68995, 69005, 69006, 69008, 69009, 69012, 69013, 69014, 69018, 69019, 69025, 69027, 69028, 69029, 69030, 69032, 69033, 69034, 69035, 69039, 69043, 69044, 69045, 69048, 69060, 69074, 69103, 69111, 69200, 69339, 69390, 69415, 69446, 69447, 69482, 69483, 69496, 69519, 69531, 69546, 69555, 69760, 69772, 69787, 69845, 69861, 69864, 69889, 69892, 69905, 69909, 69911, 69920, 69924, 69926, 69940, 69943, 69953, 69954, 69960, 69964, 69965, 69972, 69979, 69980, 69986, 70001, 70004, 70009, 70013, 70018, 70020, 70025, 70028, 70030, 70031, 70033, 70035, 70036, 70037, 70039, 70040, 70041, 70052, 70059, 70061, 70065, 70066, 70069, 70071, 70072, 70074, 70075, 70076, 70077, 70078, 70086, 70102, 70134, 70136, 70146, 70152, 70158, 70161, 70167, 70194, 70195, 70213, 70218, 70220, 70221, 70227, 70242, 70254, 70259, 70262, 70269, 70272, 70274, 70276, 70277, 70278, 70287, 70289, 70300, 70306, 70307, 70310, 70314, 70317, 70318, 70319, 70338, 70362, 70405, 70442, 70461, 70468, 70495, 70515, 70523, 70553, 70555, 70649, 70736, 70809, 70857, 70869, 70890, 70930, 70943, 70950, 70968, 70977, 70978, 70984, 70989, 70992, 70994, 70997, 70999, 71000, 71001, 71002, 71004, 71011, 71016, 71023, 71025, 71029, 71030, 71036, 71037, 71042, 71218, 71301, 71324, 71351, 71357, 71369, 71418, 71450, 71459, 71466, 71471, 71476, 71479, 71481, 71482, 71483, 71485, 71487, 71492, 71494, 71507, 71511, 71512, 71517, 71519, 71520, 71524, 71542, 71565, 71580, 71598, 71607, 71610, 71659, 71664, 71666, 71700, 71708, 71726, 71735, 71758, 71766, 71773, 71783, 71786, 71808, 71820, 71832, 71833, 71839, 71849, 71854, 71868, 71872, 71881, 71882, 71888, 71893, 71900, 71905, 71907, 71908, 71909, 71914, 71929, 71932, 71941, 71948, 71953, 71956, 71958, 71959, 71961, 71963, 71964, 71965, 71968, 71969, 71974, 71975, 71980, 71987, 71989, 71993, 71995, 71997, 71999, 72000, 72001, 72002, 72005, 72006, 72024, 72049, 72080, 72109, 72122, 72129, 72148, 72149, 72155, 72157, 72170, 72182, 72187, 72189, 72190, 72197, 72199, 72204, 72205, 72206, 72208, 72209, 72210, 72215, 72216, 72217, 72240, 72242, 72243, 72247, 72734, 72735, 72737, 72738, 72740, 72747, 72753, 72754, 72755, 72756, 72759, 72761, 72763, 72764, 72767, 72768, 72774, 72782, 72784, 72785, 72787, 72790, 72793, 72796, 72797, 72798, 72800, 72802, 72803, 72810, 72813, 72815, 72818, 72819, 72820, 72821, 72822, 72832, 72834, 72835, 72836, 72838, 72846, 72856, 72857, 72858, 72860, 72864, 72871, 72873, 72874, 72877, 72878, 72880, 72896, 72898, 72904, 72905, 72906, 72910, 72912, 72916, 72917, 72918, 72920, 72922, 72923, 72925, 72927, 72928, 72929, 72930, 72931, 72932, 72933, 72938, 72940, 72944, 72951, 72952, 72953, 72957, 72958, 72961, 72963, 72964, 72965, 72966, 72967, 72968, 72969, 72970, 72978, 72988, 73011, 73044, 73053, 73073, 73076, 73087, 73105, 73110, 73112, 73113, 73114, 73137, 73146, 73158, 73166, 73168, 73170, 73172, 73176, 73181, 73194, 73202, 73204, 73205, 73206, 73207, 73208, 73211, 73213, 73220, 73711, 74193, 74195, 74224, 74245, 74266, 74273, 74707, 74710, 74766, 74779, 74792, 74832, 74844, 74880, 75274, 75515, 75623, 75625, 75626, 75630, 75631, 75632, 75633, 75634, 75639, 75640, 75641, 75647, 75649, 75650, 75653, 75655, 75656, 75660, 75661, 75663, 75665, 75669, 75670, 75671, 75674, 75677, 75679, 75682, 75684, 75690, 75691, 75692, 75693, 75694, 75701, 75703, 75704, 75705, 75706, 75711, 75712, 75713, 75714, 75716, 75717, 75719, 75725, 75726, 75727, 75728, 75730, 75739, 75740, 75741, 75742, 75743, 75753, 75754, 75756, 75757, 75760, 75762, 75766, 75767, 75775, 75776, 75777, 75778, 75780, 75781, 75782, 75783, 75787, 75791, 75792, 75793, 75796, 75808, 75822, 75851, 75859, 76138, 76163, 76194, 76195, 76206, 76209, 76230, 76231, 76244, 76279, 76294, 76302, 76325, 76471, 76520, 76535, 76593, 76603, 76609, 76612, 76635, 76640, 76641, 76653, 76657, 76659, 76665, 76668, 76669, 76672, 76674, 76688, 76691, 76694, 76702, 76703, 76708, 76713, 76714, 76729, 76734, 76752, 76757, 76761, 76762, 76766, 76768, 76769, 76773, 76776, 76778, 76779, 76781, 76783, 76784, 76785, 76786, 76787, 76788, 76789, 76794, 76795, 76800, 76807, 76809, 76813, 76817, 76820, 76821, 76822, 76824, 76825, 76826, 76844, 76867, 76900, 76906, 76909, 76915, 76942, 76943, 76949, 76961, 76968, 76975, 76993, 77002, 77007, 77010, 77017, 77020, 77024, 77028, 77032, 77035, 77036, 77048, 77050, 77054, 77055, 77062, 77063, 77066, 77067, 77110, 77135, 77153, 77156, 77190, 77209, 77210, 77216, 77234, 77243, 77260, 77263, 77271, 77303, 77484, 77557, 77561, 77567, 77588, 77617, 77628, 77629, 77652, 77666, 77676, 77677, 77678, 77685, 77691, 77698, 77724, 77725, 77732, 77737, 77740, 77745, 77747, 77748, 77749, 77752, 77755, 77771, 77773, 77777, 77781, 77784, 77785, 77786, 77790, 77831, 77870, 77965, 77966, 78024, 78039, 78072, 78117, 78120, 78166, 78173, 78174, 78180, 78198, 78207, 78214, 78215, 78219, 78222, 78224, 78225, 78227, 78229, 78230, 78231, 78233, 78235, 78240, 78242, 78246, 78255, 78260, 78265, 78268, 78272, 78313, 78346, 78361, 78407, 78412, 78414, 78415, 78439, 78448, 78456, 78476, 78521, 78531, 78534, 78539, 78554, 78556, 78567, 78568, 78580, 78581, 78596, 78597, 78602, 78616, 78620, 78629, 78630, 78636, 78641, 78648, 78655, 78656, 78657, 78664, 78677, 78680, 78689, 78696, 78701, 78702, 78704, 78706, 78707, 78709, 78711, 78712, 78713, 78715, 78716, 78717, 78722, 78723, 78728, 78735, 78736, 78737, 78741, 78742, 78743, 78745, 78747, 78748, 78749, 78750, 78772, 78797, 78828, 78857, 78870, 78877, 78896, 78897, 78898, 78903, 78905, 78918, 78921, 78930, 78935, 78937, 78938, 78942, 78945, 78947, 78948, 78952, 78953, 78954, 78956, 78957, 78963, 78978, 78983, 78988, 78990, 78995, 79013, 79482, 79483, 79485, 79486, 79487, 79488, 79495, 79501, 79502, 79503, 79504, 79506, 79509, 79511, 79512, 79514, 79515, 79516, 79517, 79519, 79527, 79530, 79532, 79533, 79541, 79544, 79545, 79546, 79548, 79550, 79551, 79558, 79560, 79561, 79566, 79567, 79568, 79569, 79570, 79580, 79581, 79583, 79584, 79592, 79594, 79600, 79604, 79605, 79606, 79612, 79617, 79619, 79621, 79622, 79625, 79644, 79646, 79652, 79653, 79654, 79658, 79660, 79664, 79665, 79666, 79668, 79670, 79671, 79673, 79675, 79676, 79677, 79678, 79679, 79680, 79681, 79686, 79688, 79692, 79699, 79700, 79701, 79705, 79706, 79707, 79709, 79711, 79712, 79713, 79714, 79715, 79716, 79717, 79718, 79726, 79736, 79792, 79821, 79835, 79853, 79860, 79861, 79862, 79885, 79894, 79906, 79912, 79916, 79918, 79922, 79924, 79927, 79942, 79947, 79950, 79952, 79954, 79955, 79957, 79958, 79959, 80017, 80091, 80459, 80928, 80932, 81014, 81055, 81069, 81094, 81415, 81448, 81514, 81526, 81580, 81592, 81643, 82022, 82263, 82371, 82373, 82374, 82378, 82379, 82380, 82381, 82382, 82387, 82388, 82389, 82395, 82397, 82398, 82401, 82403, 82404, 82405, 82408, 82409, 82411, 82413, 82417, 82418, 82419, 82422, 82425, 82427, 82432, 82438, 82439, 82440, 82442, 82449, 82451, 82452, 82453, 82454, 82458, 82459, 82460, 82461, 82462, 82463, 82464, 82465, 82467, 82473, 82474, 82475, 82476, 82478, 82487, 82488, 82489, 82490, 82491, 82501, 82502, 82504, 82505, 82508, 82509, 82510, 82512, 82514, 82515, 82520, 82523, 82524, 82526, 82528, 82529, 82530, 82531, 82535, 82539, 82540, 82541, 82544, 82556, 82570, 82599, 82607, 82641, 82745, 82835, 82911, 82942, 82943, 82954, 82957, 82978, 82979, 82992, 83015, 83027, 83042, 83268, 83280, 83341, 83345, 83357, 83360, 83374, 83385, 83388, 83401, 83405, 83407, 83413, 83416, 83420, 83422, 83439, 83442, 83450, 83451, 83456, 83460, 83461, 83468, 83475, 83482, 83500, 83505, 83509, 83510, 83514, 83516, 83517, 83521, 83524, 83526, 83529, 83531, 83532, 83533, 83534, 83535, 83536, 83537, 83543, 83548, 83555, 83557, 83561, 83562, 83565, 83568, 83569, 83570, 83572, 83573, 83574, 83615, 83642, 83648, 83654, 83663, 83677, 83680, 83690, 83691, 83697, 83716, 83718, 83723, 83741, 83750, 83755, 83757, 83758, 83765, 83772, 83773, 83774, 83778, 83785, 83796, 83803, 83810, 83833, 83858, 83898, 83901, 83938, 83957, 83958, 83991, 83999, 84011, 84013, 84019, 84049, 84056, 84232, 84266, 84305, 84365, 84377, 84380, 84400, 84403, 84424, 84437, 84439, 84446, 84464, 84469, 84472, 84473, 84474, 84480, 84485, 84488, 84493, 84495, 84496, 84497, 84503, 84507, 84512, 84519, 84521, 84525, 84532, 84533, 84534, 84538, 84714, 84820, 84865, 84868, 84914, 84923, 84928, 84946, 84955, 84960, 84962, 84967, 84970, 84972, 84973, 84977, 84978, 84981, 84988, 84990, 85001, 85003, 85008, 85013, 85015, 85016, 85020, 85038, 85061, 85076, 85088, 85106, 85109, 85143, 85160, 85162, 85163, 85184, 85187, 85196, 85204, 85224, 85262, 85269, 85279, 85302, 85304, 85315, 85316, 85328, 85335, 85350, 85352, 85364, 85377, 85378, 85384, 85388, 85389, 85396, 85401, 85403, 85405, 85410, 85412, 85428, 85437, 85444, 85449, 85452, 85454, 85455, 85457, 85459, 85460, 85461, 85464, 85465, 85471, 85476, 85483, 85485, 85489, 85490, 85493, 85496, 85497, 85498, 85502, 85520, 85545, 85576, 85605, 85618, 85625, 85645, 85646, 85651, 85666, 85669, 85678, 85686, 85695, 85696, 85700, 85704, 85705, 85711, 85712, 85717, 85734, 85736, 85737, 85738, 85743, 86230, 86233, 86234, 86235, 86236, 86237, 86243, 86249, 86251, 86252, 86254, 86257, 86259, 86260, 86263, 86269, 86270, 86283, 86286, 86289, 86290, 86292, 86293, 86294, 86298, 86299, 86306, 86308, 86315, 86316, 86317, 86318, 86328, 86329, 86331, 86332, 86342, 86348, 86352, 86353, 86354, 86360, 86367, 86368, 86369, 86370, 86373, 86374, 86375, 86392, 86394, 86400, 86401, 86402, 86406, 86408, 86412, 86413, 86414, 86416, 86418, 86419, 86421, 86423, 86424, 86425, 86426, 86427, 86428, 86429, 86434, 86436, 86440, 86447, 86448, 86449, 86453, 86454, 86455, 86457, 86459, 86460, 86461, 86462, 86463, 86464, 86465, 86466, 86474, 86484, 86507, 86540, 86569, 86572, 86583, 86601, 86608, 86609, 86610, 86633, 86642, 86647, 86654, 86657, 86662, 86664, 86668, 86670, 86690, 86695, 86700, 86701, 86703, 86704, 86705, 86706, 86707, 87207, 87448, 87676, 87680, 87689, 87703, 87803, 88166, 88262, 88274, 88288, 88340, 88376, 88391, 88529, 88770, 89011, 89119, 89121, 89122, 89126, 89127, 89128, 89129, 89130, 89135, 89137, 89143, 89145, 89146, 89149, 89151, 89152, 89157, 89159, 89161, 89165, 89166, 89167, 89170, 89173, 89175, 89180, 89186, 89187, 89188, 89190, 89197, 89199, 89200, 89201, 89202, 89207, 89208, 89209, 89210, 89211, 89212, 89213, 89215, 89219, 89221, 89222, 89223, 89224, 89226, 89235, 89236, 89237, 89238, 89239, 89249, 89250, 89252, 89253, 89256, 89257, 89258, 89262, 89263, 89268, 89271, 89272, 89273, 89274, 89276, 89277, 89278, 89279, 89283, 89287, 89288, 89289, 89292, 89304, 89318, 89347, 89355, 89389, 89583]\n"
     ]
    }
   ],
   "source": [
    "print(len(result_list))\n",
    "print(len(token_usage_dict_list))\n",
    "print(f\"Number of samples that are not returned: {len(not_returned)}\")\n",
    "print(f\"Custom IDs of the not returned samples that are not returned: {not_returned}\")\n",
    "print(f\"Number of samples that are filtered: {len(filtered)}\")\n",
    "print(f\"Custom IDs of the not returned samples that are filtered: {filtered}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- dobutamine (active)\n",
      "- Nipride (active)\n",
      "- Esmolol (discontinued)\n",
      "{'completion_tokens': 21, 'prompt_tokens': 254, 'total_tokens': 275}\n"
     ]
    }
   ],
   "source": [
    "print(result_list[0])\n",
    "print(token_usage_dict_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total input tokens: 55097725\n",
      "Total output tokens: 6479691\n",
      "Total tokens: 61577416\n"
     ]
    }
   ],
   "source": [
    "total_input = 0\n",
    "total_output = 0\n",
    "total_all = 0\n",
    "for element in token_usage_dict_list:\n",
    "    if len(element) > 0:\n",
    "        total_input += element[\"prompt_tokens\"]\n",
    "        total_output += element[\"completion_tokens\"]\n",
    "        total_all += element[\"total_tokens\"]\n",
    "\n",
    "print(f\"Total input tokens: {total_input}\\nTotal output tokens: {total_output}\\nTotal tokens: {total_all}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *token_usage_dict_list* will look like [{'completion_tokens': 28, 'prompt_tokens': 21, 'total_tokens': 49}, {'completion_tokens': 208, 'prompt_tokens': 16, 'total_tokens': 224}], where *completion_tokens* is the **output** token, *prompt_tokens* is the **input** token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# process result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 14 prompt templates for prefix \"Other\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1923687/4030179815.py:130: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  result_df = pd.concat([result_df, new_row], axis=0, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 14 prompt templates for prefix \"Other\"\n",
      "Loaded 14 prompt templates for prefix \"Internal Data\"\n"
     ]
    }
   ],
   "source": [
    "from vllm_inference import *\n",
    "\n",
    "\n",
    "# 3. Update run_pipeline to use LLMEngine and align with the original logic\n",
    "def run_llm_pipeline(input_df, response_list, dataset_name):\n",
    "    \"\"\"\n",
    "    Main function to run the text generation pipeline using LLMEngine and compute metrics.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    llm_model : str\n",
    "        The initilized llm model.\n",
    "    input_df : pd.DataFrame\n",
    "        The data to be inferred.\n",
    "    prompt_template : str\n",
    "        Template for constructing the prompts.\n",
    "    dataset_name : str\n",
    "        Name of the dataset. Used for special cases like Internal Data exclusion.\n",
    "    batch_size : int\n",
    "        Number of examples per batch.\n",
    "    max_token_output : int\n",
    "        Maximum number of tokens to generate.\n",
    "    use_sampling : bool\n",
    "        Whether to use sampling (or greedy decoding).\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "    result_df : pd.DataFrame\n",
    "        DataFrame with the processed outputs and calculated metrics.\n",
    "    \"\"\"\n",
    "    # Generate responses\n",
    "    response_list_wo_groundtruth, response_list_with_groundtruth = response_list\n",
    "\n",
    "    # Process the responses to categorize medications\n",
    "    df_w_classifications = process_output(input_df, response_list_wo_groundtruth, dataset_name)  \n",
    "    # process the responses with ground truth to categorize medications\n",
    "    df_w_classifications_with_groundtruth = process_output(input_df, response_list_with_groundtruth, dataset_name)\n",
    "\n",
    "    # Calculate row-level metrics\n",
    "    extraction_precision, extraction_recall, extraction_f1, joint_accuracy, joint_macro_f1, joint_macro_precision, joint_macro_recall = calculate_metrics_by_dataset(df_w_classifications, dataset_name)\n",
    "    # calculate the classification metrics with responses with ground truth\n",
    "    accuracy, macro_f1, macro_precision, macro_recall = calculate_classification_metrics(df_w_classifications_with_groundtruth, dataset_name)\n",
    "\n",
    "    # append the active_medications_pred, discontinued_medications_pred, neither_medications_pred to the df_w_classifications with extension of _with_groundtruth\n",
    "    df_w_classifications_with_groundtruth = df_w_classifications_with_groundtruth[['model_response', 'active_medications_pred', 'discontinued_medications_pred', 'neither_medications_pred']] if dataset_name != \"Internal Data\" else df_w_classifications_with_groundtruth[['model_response', 'active_medications_pred', 'discontinued_medications_pred']]\n",
    "    df_w_classifications_with_groundtruth.columns = [f'{col}_with_groundtruth' for col in df_w_classifications_with_groundtruth.columns]\n",
    "    df_w_classifications = pd.concat([df_w_classifications, df_w_classifications_with_groundtruth], axis=1)\n",
    "\n",
    "    # Return the final DataFrame with metrics\n",
    "    return df_w_classifications, extraction_precision, extraction_recall, extraction_f1, joint_accuracy, joint_macro_f1, joint_macro_precision, joint_macro_recall, accuracy, macro_f1, macro_precision, macro_recall\n",
    "\n",
    "\n",
    "def json_metric_calculation(dataset_name, result_list, input_df, data_folder, result_df_path):\n",
    "\n",
    "    model_name = 'gpt-4o'\n",
    "    \n",
    "    # Check if input_df.active_medications[0] is a list, if not, apply eval and lower to medications\n",
    "    if not isinstance(input_df.active_medications[0], list):\n",
    "        input_df.loc[:, 'active_medications'] = input_df['active_medications'].apply(lambda x: literal_eval(x)).apply(lambda x: [med.lower() for med in x])\n",
    "        input_df.loc[:, 'discontinued_medications'] = input_df['discontinued_medications'].apply(lambda x: literal_eval(x)).apply(lambda x: [med.lower() for med in x])\n",
    "        if dataset_name != \"Internal Data\":\n",
    "            input_df.loc[:, 'neither_medications'] = input_df['neither_medications'].apply(lambda x: literal_eval(x)).apply(lambda x: [med.lower() for med in x])\n",
    "    \n",
    "    col_list = ['active_medications', 'discontinued_medications', 'neither_medications'] if dataset_name != \"Internal Data\" else ['active_medications', 'discontinued_medications']\n",
    "    input_df['true_set'] = input_df[col_list].apply(lambda x: set([med for meds in x for med in meds]), axis=1)\n",
    "\n",
    "    prompt_prefix = 'Other' if dataset_name != \"Internal Data\" else 'Internal Data'\n",
    "    prompt_templates_with_keys = load_prompt_templates('prompts.json', prompt_prefix)\n",
    "    length_of_content_per_prompt = len(result_list)//len(prompt_templates_with_keys)\n",
    "\n",
    "    count_per_sim = len(result_list)//5\n",
    "\n",
    "    for sim in range(5):\n",
    "\n",
    "        for idx, prompt in enumerate(prompt_templates_with_keys):\n",
    "            prompt_key, prompt_template = prompt\n",
    "\n",
    "            # get the content for simulation sim\n",
    "            results_sim = result_list[sim*count_per_sim:(sim+1)*count_per_sim]\n",
    "            length_of_content_per_prompt = len(results_sim)//len(prompt_templates_with_keys)\n",
    "            \n",
    "            # get the content for prompt idx\n",
    "            results_prompt = results_sim[idx*length_of_content_per_prompt:(idx+1)*length_of_content_per_prompt]\n",
    "            # get the content without the hint\n",
    "            results_prompt_without_hint = results_prompt[:length_of_content_per_prompt//2]\n",
    "            # get the content with the hint\n",
    "            results_prompt_with_hint = results_prompt[length_of_content_per_prompt//2:]\n",
    "\n",
    "            # Run the LLMEngine pipeline\n",
    "            df_w_classifications, extraction_precision, extraction_recall, extraction_f1, joint_accuracy, \\\n",
    "            joint_macro_f1, joint_macro_precision, joint_macro_recall, accuracy, macro_f1, macro_precision, \\\n",
    "            macro_recall = run_llm_pipeline(\n",
    "                input_df = input_df, \n",
    "                response_list = (results_prompt_without_hint, results_prompt_with_hint),\n",
    "                dataset_name = dataset_name\n",
    "            )\n",
    "\n",
    "            # Save the row metrics DataFrame to a CSV\n",
    "            output_filename = f'{dataset_name}_{model_name}_sim_{sim}_{prompt_key}.csv'\n",
    "            df_w_classifications.to_csv(data_folder + f'base_pred_data/{output_filename}', index=False)\n",
    "\n",
    "            # Read the results CSV\n",
    "            result_df = pd.read_csv(result_df_path)\n",
    "\n",
    "            # Define your result row\n",
    "            new_row = {\n",
    "                'Dataset': dataset_name,\n",
    "                'Model': model_name,\n",
    "                'Prompt': prompt_template,\n",
    "                'Simulation': sim,\n",
    "\n",
    "                'extraction_precision': extraction_precision,\n",
    "                'extraction_recall': extraction_recall,\n",
    "                'extraction_f1': extraction_f1,\n",
    "\n",
    "                'accuracy_w_gt': accuracy,\n",
    "                'macro_f1_w_gt': macro_f1,\n",
    "                'macro_precision_w_gt': macro_precision,\n",
    "                'macro_recall_w_gt': macro_recall,\n",
    "\n",
    "                'joint_accuracy': joint_accuracy,\n",
    "                'joint_macro_f1': joint_macro_f1,\n",
    "                'joint_macro_precision': joint_macro_precision,\n",
    "                'joint_macro_recall': joint_macro_recall,\n",
    "            }\n",
    "\n",
    "            new_row = pd.DataFrame([new_row])\n",
    "\n",
    "            # Append the new row to the results DataFrame and save\n",
    "            result_df = pd.concat([result_df, new_row], axis=0, ignore_index=True)\n",
    "            result_df.to_csv(result_df_path, index=False)\n",
    "\n",
    "# split the result into 3 datasets\n",
    "result_MIT = result_list[:len(input_for_MIT)*5]\n",
    "result_MIMIV = result_list[len(input_for_MIT)*5:len(input_for_MIT)*5+len(input_for_MIMIV)*5]\n",
    "result_internal_data = result_list[-len(input_for_internal_data)*5:]\n",
    "\n",
    "\n",
    "data_folder = '/PHShome/cs1839/capstone_data/'\n",
    "MIT = pd.read_csv(data_folder + 'medication_status_test.csv')\n",
    "MIMIV = pd.read_csv(data_folder + 'mimic_iv_snippets_list_new.csv')\n",
    "internal_data = pd.read_csv(data_folder + 'PPV_snippet_medications.csv')\n",
    "\n",
    "json_metric_calculation(dataset_name='MIT',\n",
    "                        result_list=result_MIT,\n",
    "                        input_df=MIT,\n",
    "                        data_folder=data_folder,\n",
    "                        result_df_path=data_folder + 'results_gpt4o.csv')\n",
    "\n",
    "json_metric_calculation(dataset_name=\"MIMIC-IV\",\n",
    "                        result_list=result_MIMIV,\n",
    "                        input_df=MIMIV,\n",
    "                        data_folder=data_folder,\n",
    "                        result_df_path=data_folder + 'results_gpt4o.csv')\n",
    "\n",
    "json_metric_calculation(dataset_name='Internal Data',\n",
    "                        result_list=result_internal_data,\n",
    "                        input_df=internal_data,\n",
    "                        data_folder=data_folder,\n",
    "                        result_df_path=data_folder + 'results_gpt4o.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
